{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERDL Pangenome Data Exploration\n",
    "\n",
    "Exploratory data analysis of the KBase pangenome database containing:\n",
    "- **293,059 genomes** across **27,690 species-level clades**\n",
    "- Gene clusters, functional annotations, and ANI metrics\n",
    "- GTDB taxonomy and quality metadata\n",
    "\n",
    "**Database**: `kbase_ke_pangenome` in BERDL Data Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load authentication token from .env\n",
    "with open('.env', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('KB_AUTH_TOKEN'):\n",
    "            AUTH_TOKEN = line.split('\"')[1]\n",
    "            break\n",
    "\n",
    "# BERDL API configuration\n",
    "BASE_URL = \"https://hub.berdl.kbase.us/apis/mcp\"\n",
    "DATABASE = \"kbase_ke_pangenome\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(f\"✅ Connected to BERDL API: {BASE_URL}\")\n",
    "print(f\"✅ Database: {DATABASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def query_berdl(sql: str, limit: int = 10000, offset: int = 0) -> pd.DataFrame:\n    \"\"\"Execute a SQL query against BERDL and return results as DataFrame.\"\"\"\n    url = f\"{BASE_URL}/delta/tables/query\"\n    payload = {\n        \"query\": sql,\n        \"limit\": limit,\n        \"offset\": offset\n    }\n    \n    response = requests.post(url, headers=HEADERS, json=payload)\n    response.raise_for_status()\n    \n    data = response.json()\n    \n    # Handle both 'result' and 'results' keys (API format changed)\n    results = data.get('result', data.get('results', []))\n    \n    if results and len(results) > 0:\n        return pd.DataFrame(results)\n    else:\n        return pd.DataFrame()\n\ndef get_table_count(table: str) -> int:\n    \"\"\"Get total row count for a table.\"\"\"\n    url = f\"{BASE_URL}/delta/tables/count\"\n    payload = {\"database\": DATABASE, \"table\": table}\n    \n    response = requests.post(url, headers=HEADERS, json=payload)\n    response.raise_for_status()\n    \n    return response.json()['count']\n\ndef get_table_schema(table: str) -> List[str]:\n    \"\"\"Get column names for a table.\"\"\"\n    url = f\"{BASE_URL}/delta/databases/tables/schema\"\n    payload = {\"database\": DATABASE, \"table\": table}\n    \n    response = requests.post(url, headers=HEADERS, json=payload)\n    response.raise_for_status()\n    \n    return response.json()['columns']\n\ndef sample_table(table: str, limit: int = 5) -> pd.DataFrame:\n    \"\"\"Get a sample of rows from a table.\"\"\"\n    url = f\"{BASE_URL}/delta/tables/sample\"\n    payload = {\"database\": DATABASE, \"table\": table, \"limit\": limit}\n    \n    response = requests.post(url, headers=HEADERS, json=payload)\n    response.raise_for_status()\n    \n    data = response.json()\n    return pd.DataFrame(data['sample'])\n\nprint(\"✅ Helper functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get table counts with timeout handling\nimport time\n\ntables = ['genome', 'pangenome', 'gtdb_species_clade', 'gene_cluster', \n          'eggnog_mapper_annotations', 'gapmind_pathways', 'genome_ani']\n\ntable_info = []\nfor table in tables:\n    try:\n        print(f\"Fetching info for {table}...\", end=\" \")\n        count = get_table_count(table)\n        columns = get_table_schema(table)\n        table_info.append({\n            'Table': table,\n            'Row Count': f\"{count:,}\",\n            'Columns': len(columns)\n        })\n        print(\"✓\")\n    except requests.exceptions.HTTPError as e:\n        if '504' in str(e) or '503' in str(e):\n            print(f\"⏱ Timeout (will skip)\")\n            table_info.append({\n                'Table': table,\n                'Row Count': 'Timeout - Table too large',\n                'Columns': 'N/A'\n            })\n        else:\n            print(f\"✗ Error: {e}\")\n            table_info.append({\n                'Table': table,\n                'Row Count': 'Error',\n                'Columns': 'N/A'\n            })\n    except Exception as e:\n        print(f\"✗ Error: {e}\")\n        table_info.append({\n            'Table': table,\n            'Row Count': 'Error',\n            'Columns': 'N/A'\n        })\n    time.sleep(0.5)  # Small delay between requests\n\ndf_tables = pd.DataFrame(table_info)\ndisplay(df_tables)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Species-Level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Distribution of Genomes per Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query pangenome statistics\n",
    "sql = f\"\"\"\n",
    "SELECT \n",
    "    p.gtdb_species_clade_id,\n",
    "    s.GTDB_species,\n",
    "    s.GTDB_taxonomy,\n",
    "    p.no_genomes,\n",
    "    p.no_core,\n",
    "    p.no_aux_genome as no_accessory,\n",
    "    p.no_singleton_gene_clusters as no_singletons,\n",
    "    p.no_gene_clusters,\n",
    "    s.mean_intra_species_ANI,\n",
    "    s.ANI_circumscription_radius\n",
    "FROM {DATABASE}.pangenome p\n",
    "JOIN {DATABASE}.gtdb_species_clade s \n",
    "    ON p.gtdb_species_clade_id = s.gtdb_species_clade_id\n",
    "ORDER BY p.no_genomes DESC\n",
    "\"\"\"\n",
    "\n",
    "df_pangenome = query_berdl(sql, limit=30000)\n",
    "print(f\"Loaded {len(df_pangenome):,} species pangenomes\")\n",
    "df_pangenome.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of genomes per species\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Distribution of Genomes per Species', 'Log Scale')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df_pangenome['no_genomes'], nbinsx=50, name='Linear'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df_pangenome['no_genomes'], nbinsx=50, name='Log'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Genomes per Species\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Genomes per Species (log)\", type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Number of Species\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Number of Species\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, showlegend=False, title_text=\"Genome Sampling Across Species\")\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nGenomes per species statistics:\")\n",
    "print(df_pangenome['no_genomes'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Top Species by Genome Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 species by genome count\n",
    "top_species = df_pangenome.nlargest(20, 'no_genomes')[['GTDB_species', 'no_genomes', 'no_core', 'no_accessory']]\n",
    "\n",
    "fig = px.bar(\n",
    "    top_species, \n",
    "    x='no_genomes', \n",
    "    y='GTDB_species',\n",
    "    orientation='h',\n",
    "    title='Top 20 Species by Genome Count',\n",
    "    labels={'no_genomes': 'Number of Genomes', 'GTDB_species': 'Species'},\n",
    "    height=600\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()\n",
    "\n",
    "display(top_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pangenome Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Core vs Accessory vs Singleton Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages\n",
    "df_pangenome['pct_core'] = (df_pangenome['no_core'] / df_pangenome['no_gene_clusters'] * 100).round(2)\n",
    "df_pangenome['pct_accessory'] = (df_pangenome['no_accessory'] / df_pangenome['no_gene_clusters'] * 100).round(2)\n",
    "df_pangenome['pct_singletons'] = (df_pangenome['no_singletons'] / df_pangenome['no_gene_clusters'] * 100).round(2)\n",
    "\n",
    "# Summary stats\n",
    "print(\"Pangenome composition (%):\\n\")\n",
    "print(df_pangenome[['pct_core', 'pct_accessory', 'pct_singletons']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: Core genes vs genome count\n",
    "fig = px.scatter(\n",
    "    df_pangenome.sample(min(5000, len(df_pangenome))),\n",
    "    x='no_genomes',\n",
    "    y='pct_core',\n",
    "    color='pct_singletons',\n",
    "    title='Core Gene Percentage vs Genome Sampling',\n",
    "    labels={\n",
    "        'no_genomes': 'Number of Genomes in Species',\n",
    "        'pct_core': 'Core Genes (%)',\n",
    "        'pct_singletons': 'Singletons (%)'\n",
    "    },\n",
    "    hover_data=['GTDB_species'],\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Open vs Closed Pangenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accessory:core ratio (higher = more open)\n",
    "df_pangenome['accessory_core_ratio'] = (df_pangenome['no_accessory'] / df_pangenome['no_core']).round(2)\n",
    "\n",
    "# Filter species with at least 10 genomes for meaningful analysis\n",
    "df_filtered = df_pangenome[df_pangenome['no_genomes'] >= 10].copy()\n",
    "\n",
    "fig = px.histogram(\n",
    "    df_filtered,\n",
    "    x='accessory_core_ratio',\n",
    "    nbins=50,\n",
    "    title='Pangenome Openness (Accessory:Core Ratio, species with ≥10 genomes)',\n",
    "    labels={'accessory_core_ratio': 'Accessory:Core Gene Ratio'},\n",
    "    marginal='box'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nAccessory:Core ratio statistics (species with ≥10 genomes):\")\n",
    "print(df_filtered['accessory_core_ratio'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Taxonomic Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse taxonomy into levels\n",
    "def parse_taxonomy(tax_string):\n",
    "    \"\"\"Parse GTDB taxonomy string into components.\"\"\"\n",
    "    levels = {}\n",
    "    if pd.isna(tax_string):\n",
    "        return levels\n",
    "    \n",
    "    parts = tax_string.split(';')\n",
    "    for part in parts:\n",
    "        if '__' in part:\n",
    "            level, name = part.split('__', 1)\n",
    "            levels[level] = name\n",
    "    return levels\n",
    "\n",
    "# Extract phylum and class\n",
    "tax_parsed = df_pangenome['GTDB_taxonomy'].apply(parse_taxonomy)\n",
    "df_pangenome['phylum'] = tax_parsed.apply(lambda x: x.get('p', 'Unknown'))\n",
    "df_pangenome['class'] = tax_parsed.apply(lambda x: x.get('c', 'Unknown'))\n",
    "\n",
    "print(\"✅ Taxonomy parsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Species Count by Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count species per phylum\n",
    "phylum_counts = df_pangenome['phylum'].value_counts().head(20)\n",
    "\n",
    "fig = px.bar(\n",
    "    x=phylum_counts.values,\n",
    "    y=phylum_counts.index,\n",
    "    orientation='h',\n",
    "    title='Top 20 Phyla by Species Count',\n",
    "    labels={'x': 'Number of Species', 'y': 'Phylum'},\n",
    "    height=600\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Genome Sampling by Phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total genomes per phylum\n",
    "genomes_by_phylum = df_pangenome.groupby('phylum')['no_genomes'].sum().sort_values(ascending=False).head(20)\n",
    "\n",
    "fig = px.bar(\n",
    "    x=genomes_by_phylum.values,\n",
    "    y=genomes_by_phylum.index,\n",
    "    orientation='h',\n",
    "    title='Top 20 Phyla by Total Genome Count',\n",
    "    labels={'x': 'Total Genomes', 'y': 'Phylum'},\n",
    "    height=600\n",
    ")\n",
    "fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ANI (Average Nucleotide Identity) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANI distribution across species\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Mean Intra-Species ANI', 'ANI Circumscription Radius')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df_pangenome['mean_intra_species_ANI'], nbinsx=50, name='Mean ANI'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df_pangenome['ANI_circumscription_radius'], nbinsx=50, name='Circumscription'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"ANI (%)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"ANI Radius (%)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Number of Species\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Number of Species\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nANI Statistics:\")\n",
    "print(df_pangenome[['mean_intra_species_ANI', 'ANI_circumscription_radius']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sample Species Deep Dive\n",
    "\n",
    "Let's look at a specific well-sampled species in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pick the most sampled species\ntop_species_id = df_pangenome.nlargest(1, 'no_genomes')['gtdb_species_clade_id'].values[0]\ntop_species_name = df_pangenome.nlargest(1, 'no_genomes')['GTDB_species'].values[0]\n\nprint(f\"Exploring: {top_species_name}\")\nprint(f\"Species ID: {top_species_id}\")\n\n# Use LIKE query to avoid '--' metacharacter issue\nspecies_name_for_query = top_species_name.replace('s__', '')\n\nsql = f\"\"\"\nSELECT \n    g.genome_id,\n    g.gtdb_species_clade_id,\n    g.ncbi_biosample_id,\n    m.checkm_completeness,\n    m.checkm_contamination,\n    m.genome_size,\n    m.gc_percentage,\n    m.contig_count\nFROM {DATABASE}.genome g\nLEFT JOIN {DATABASE}.gtdb_metadata m ON g.genome_id = m.accession\nWHERE g.gtdb_species_clade_id LIKE '%{species_name_for_query}%'\nLIMIT 500\n\"\"\"\n\nprint(f\"\\nFetching genomes for {top_species_name}...\")\ndf_species_genomes = query_berdl(sql, limit=500)\n\nif df_species_genomes is not None and len(df_species_genomes) > 0:\n    # Convert string columns to numeric\n    numeric_cols = ['checkm_completeness', 'checkm_contamination', 'genome_size', 'gc_percentage', 'contig_count']\n    for col in numeric_cols:\n        if col in df_species_genomes.columns:\n            df_species_genomes[col] = pd.to_numeric(df_species_genomes[col], errors='coerce')\n    \n    print(f\"✅ Loaded {len(df_species_genomes)} genomes\")\n    display(df_species_genomes.head(10))\nelse:\n    print(\"❌ Failed to fetch genome data\")\n    df_species_genomes = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quality metrics for this species\nif df_species_genomes is not None and len(df_species_genomes) > 0:\n    # Check which columns are available\n    has_completeness = 'checkm_completeness' in df_species_genomes.columns\n    has_contamination = 'checkm_contamination' in df_species_genomes.columns\n    has_size = 'genome_size' in df_species_genomes.columns\n    has_gc = 'gc_percentage' in df_species_genomes.columns\n    \n    if has_completeness or has_contamination or has_size or has_gc:\n        fig = make_subplots(\n            rows=2, cols=2,\n            subplot_titles=(\n                'Genome Completeness' if has_completeness else 'N/A',\n                'Contamination' if has_contamination else 'N/A',\n                'Genome Size' if has_size else 'N/A',\n                'GC Content' if has_gc else 'N/A'\n            )\n        )\n        \n        if has_completeness:\n            fig.add_trace(\n                go.Histogram(x=df_species_genomes['checkm_completeness'].dropna(), nbinsx=30),\n                row=1, col=1\n            )\n        \n        if has_contamination:\n            fig.add_trace(\n                go.Histogram(x=df_species_genomes['checkm_contamination'].dropna(), nbinsx=30),\n                row=1, col=2\n            )\n        \n        if has_size:\n            fig.add_trace(\n                go.Histogram(x=df_species_genomes['genome_size'].dropna(), nbinsx=30),\n                row=2, col=1\n            )\n        \n        if has_gc:\n            fig.add_trace(\n                go.Histogram(x=df_species_genomes['gc_percentage'].dropna(), nbinsx=30),\n                row=2, col=2\n            )\n        \n        fig.update_xaxes(title_text=\"Completeness (%)\", row=1, col=1)\n        fig.update_xaxes(title_text=\"Contamination (%)\", row=1, col=2)\n        fig.update_xaxes(title_text=\"Size (bp)\", row=2, col=1)\n        fig.update_xaxes(title_text=\"GC %\", row=2, col=2)\n        \n        fig.update_layout(height=800, showlegend=False, title_text=f\"Genome Quality Metrics: {top_species_name}\")\n        fig.show()\n        \n        # Print summary stats\n        if has_completeness:\n            print(f\"\\nCompleteness: mean={df_species_genomes['checkm_completeness'].mean():.2f}%, median={df_species_genomes['checkm_completeness'].median():.2f}%\")\n        if has_contamination:\n            print(f\"Contamination: mean={df_species_genomes['checkm_contamination'].mean():.2f}%, median={df_species_genomes['checkm_contamination'].median():.2f}%\")\n        if has_size:\n            print(f\"Genome size: mean={df_species_genomes['genome_size'].mean()/1e6:.2f} Mbp, median={df_species_genomes['genome_size'].median()/1e6:.2f} Mbp\")\n        if has_gc:\n            print(f\"GC content: mean={df_species_genomes['gc_percentage'].mean():.2f}%, median={df_species_genomes['gc_percentage'].median():.2f}%\")\n    else:\n        print(\"⚠️ No quality metric columns available in the data\")\nelse:\n    print(\"⚠️ No genome data available for quality metrics visualization\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall dataset summary\n",
    "summary = {\n",
    "    'Total Species': len(df_pangenome),\n",
    "    'Total Genomes': df_pangenome['no_genomes'].sum(),\n",
    "    'Median Genomes/Species': df_pangenome['no_genomes'].median(),\n",
    "    'Median Core Genes': df_pangenome['no_core'].median(),\n",
    "    'Median Accessory Genes': df_pangenome['no_accessory'].median(),\n",
    "    'Median Singleton Genes': df_pangenome['no_singletons'].median(),\n",
    "    'Mean ANI (%)': df_pangenome['mean_intra_species_ANI'].mean(),\n",
    "    'Unique Phyla': df_pangenome['phylum'].nunique(),\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(list(summary.items()), columns=['Metric', 'Value'])\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "Potential analyses to explore:\n",
    "\n",
    "1. **Functional Analysis**: Query `eggnog_mapper_annotations` and `gapmind_pathways` for functional enrichment\n",
    "2. **Mobile Elements**: Analyze `genomad_mobile_elements` for plasmid/virus patterns\n",
    "3. **Pairwise ANI**: Explore `genome_ani` table for within-species diversity\n",
    "4. **Gene Cluster Analysis**: Dive into `gene_cluster` and `gene_genecluster_junction` tables\n",
    "5. **Environment Correlations**: Link to `sample` and `ncbi_env` metadata\n",
    "6. **Phylogenetic Patterns**: Compare ANI vs phylogenetic distance\n",
    "7. **Species-specific Analyses**: Deep dives into specific clades of interest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}