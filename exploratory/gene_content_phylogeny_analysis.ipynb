{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Gene Content vs Phylogenetic Distance Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook investigates the relationship between **gene content** (pangenome structure) and **phylogenetic distance** across bacterial species. The central question is:\n",
    "\n",
    "> **Does phylogenetic relatedness predict gene content similarity?**\n",
    "\n",
    "We hypothesize that closely related species should have more similar pangenome characteristics (core genome size, openness) than distantly related species. However, ecological factors and horizontal gene transfer may weaken this signal.\n",
    "\n",
    "### Data Sources\n",
    "- **Pangenome data**: KBase BERDL pangenome database (27,690 species, 293,059 genomes)\n",
    "- **Phylogenetic tree**: GTDB r214 bacterial tree (`bac120.tree`) with 136,646 representative genomes\n",
    "- **Taxonomy**: GTDB taxonomy for hierarchical comparisons\n",
    "\n",
    "### Analysis Steps\n",
    "1. Load and filter species data (quality control)\n",
    "2. Match species to phylogenetic tree via representative genomes\n",
    "3. Compute phylogenetic distance matrix\n",
    "4. Compute gene content distance matrices (multiple metrics)\n",
    "5. Analyze correlation at global and taxonomic levels\n",
    "6. Visualize results and interpret findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Load authentication token for BERDL API\n",
    "with open('.env', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('KB_AUTH_TOKEN'):\n",
    "            AUTH_TOKEN = line.split('\"')[1]\n",
    "            break\n",
    "\n",
    "# BERDL API configuration\n",
    "BASE_URL = \"https://hub.berdl.kbase.us/apis/mcp\"\n",
    "DATABASE = \"kbase_ke_pangenome\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {AUTH_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "def query_berdl(sql, limit=10000, offset=0):\n",
    "    \"\"\"Execute a SQL query against BERDL.\"\"\"\n",
    "    url = f\"{BASE_URL}/delta/tables/query\"\n",
    "    payload = {\"query\": sql, \"limit\": limit, \"offset\": offset}\n",
    "    response = requests.post(url, headers=HEADERS, json=payload)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    results = data.get('result', data.get('results', []))\n",
    "    return pd.DataFrame(results) if results else pd.DataFrame()\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"BERDL database: {DATABASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## 2. Load Pangenome Data\n",
    "\n",
    "We load species-level pangenome statistics joined with taxonomic information. Key fields include:\n",
    "- `no_genomes`: Number of genomes in the species (sampling depth)\n",
    "- `no_core`: Number of core genes (present in >95% of genomes)\n",
    "- `no_aux_genome`: Number of accessory genes (5-95%)\n",
    "- `no_singleton_gene_clusters`: Genes found in only one genome\n",
    "- `mean_intra_species_ANI`: Average nucleotide identity within species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full pangenome data with taxonomy\n",
    "sql = f\"\"\"\n",
    "SELECT \n",
    "    p.gtdb_species_clade_id,\n",
    "    s.GTDB_species,\n",
    "    s.GTDB_taxonomy,\n",
    "    p.no_genomes,\n",
    "    p.no_core,\n",
    "    p.no_aux_genome as no_accessory,\n",
    "    p.no_singleton_gene_clusters as no_singletons,\n",
    "    p.no_gene_clusters,\n",
    "    p.no_CDSes,\n",
    "    s.mean_intra_species_ANI,\n",
    "    s.ANI_circumscription_radius\n",
    "FROM {DATABASE}.pangenome p\n",
    "JOIN {DATABASE}.gtdb_species_clade s \n",
    "    ON p.gtdb_species_clade_id = s.gtdb_species_clade_id\n",
    "ORDER BY p.no_genomes DESC\n",
    "\"\"\"\n",
    "\n",
    "df_raw = query_berdl(sql, limit=30000)\n",
    "print(f\"Loaded {len(df_raw):,} species from BERDL\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-filter-header",
   "metadata": {},
   "source": [
    "## 3. Quality Filtering\n",
    "\n",
    "Before analysis, we apply quality filters to ensure reliable pangenome statistics:\n",
    "\n",
    "### Filter Criteria\n",
    "1. **Minimum genome count**: Species with very few genomes have unreliable core/accessory estimates\n",
    "   - Pangenome structure requires sampling multiple strains\n",
    "   - We'll use a minimum threshold (e.g., 5-10 genomes)\n",
    "   \n",
    "2. **Valid pangenome statistics**: Remove species with missing or zero values\n",
    "\n",
    "3. **Reasonable ANI values**: Filter out potential contaminated or misclassified species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality filtering parameters\n",
    "MIN_GENOMES = 10  # Minimum number of genomes per species\n",
    "MIN_CORE_GENES = 100  # Minimum core genome size\n",
    "MIN_ANI = 95.0  # Minimum ANI (GTDB species boundary)\n",
    "\n",
    "print(\"Quality Filter Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Raw species count: {len(df_raw):,}\")\n",
    "\n",
    "# Apply filters step by step\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Filter 1: Minimum genomes\n",
    "n_before = len(df)\n",
    "df = df[df['no_genomes'] >= MIN_GENOMES]\n",
    "print(f\"After min genomes >= {MIN_GENOMES}: {len(df):,} ({n_before - len(df):,} removed)\")\n",
    "\n",
    "# Filter 2: Valid core genome\n",
    "n_before = len(df)\n",
    "df = df[df['no_core'] >= MIN_CORE_GENES]\n",
    "print(f\"After min core genes >= {MIN_CORE_GENES}: {len(df):,} ({n_before - len(df):,} removed)\")\n",
    "\n",
    "# Filter 3: Valid ANI\n",
    "n_before = len(df)\n",
    "df = df[df['mean_intra_species_ANI'] >= MIN_ANI]\n",
    "print(f\"After min ANI >= {MIN_ANI}: {len(df):,} ({n_before - len(df):,} removed)\")\n",
    "\n",
    "# Filter 4: Non-null singletons\n",
    "n_before = len(df)\n",
    "df = df[df['no_singletons'].notna()]\n",
    "print(f\"After removing null singletons: {len(df):,} ({n_before - len(df):,} removed)\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Final filtered species: {len(df):,}\")\n",
    "print(f\"Total genomes represented: {df['no_genomes'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse taxonomy and compute derived metrics\n",
    "def parse_taxonomy(tax_string):\n",
    "    \"\"\"Parse GTDB taxonomy string into levels.\"\"\"\n",
    "    levels = {}\n",
    "    if pd.isna(tax_string):\n",
    "        return levels\n",
    "    for part in tax_string.split(';'):\n",
    "        if '__' in part:\n",
    "            level, name = part.split('__', 1)\n",
    "            levels[level] = name\n",
    "    return levels\n",
    "\n",
    "# Extract taxonomy levels\n",
    "tax_parsed = df['GTDB_taxonomy'].apply(parse_taxonomy)\n",
    "df['domain'] = tax_parsed.apply(lambda x: x.get('d', 'Unknown'))\n",
    "df['phylum'] = tax_parsed.apply(lambda x: x.get('p', 'Unknown'))\n",
    "df['class'] = tax_parsed.apply(lambda x: x.get('c', 'Unknown'))\n",
    "df['order'] = tax_parsed.apply(lambda x: x.get('o', 'Unknown'))\n",
    "df['family'] = tax_parsed.apply(lambda x: x.get('f', 'Unknown'))\n",
    "df['genus'] = tax_parsed.apply(lambda x: x.get('g', 'Unknown'))\n",
    "\n",
    "# Compute pangenome metrics\n",
    "df['pct_core'] = (df['no_core'] / df['no_gene_clusters'] * 100).round(2)\n",
    "df['pct_accessory'] = (df['no_accessory'] / df['no_gene_clusters'] * 100).round(2)\n",
    "df['pct_singletons'] = (df['no_singletons'] / df['no_gene_clusters'] * 100).round(2)\n",
    "df['openness'] = (df['no_accessory'] / df['no_core']).round(3)  # Higher = more open pangenome\n",
    "df['avg_genes_per_genome'] = (df['no_CDSes'] / df['no_genomes']).round(0)\n",
    "\n",
    "# Extract representative genome ID from gtdb_species_clade_id\n",
    "# Format: s__Species_name--RS_GCF_XXXXXX.X or --GB_GCA_XXXXXX.X\n",
    "df['rep_genome'] = df['gtdb_species_clade_id'].str.extract(r'--((?:RS_GCF|GB_GCA)_\\d+\\.\\d+)')[0]\n",
    "\n",
    "print(f\"Computed metrics for {len(df):,} species\")\n",
    "print(f\"\\nPangenome statistics:\")\n",
    "print(df[['no_genomes', 'no_core', 'pct_core', 'openness', 'avg_genes_per_genome']].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the filtering impact and data distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Genome count distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(df['no_genomes'], bins=50, edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Number of Genomes per Species')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title(f'Genome Sampling Depth (n={len(df):,} species)')\n",
    "ax1.axvline(df['no_genomes'].median(), color='red', linestyle='--', \n",
    "            label=f'Median: {df[\"no_genomes\"].median():.0f}')\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Core genome % distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(df['pct_core'], bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "ax2.set_xlabel('Core Genome (%)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Core Genome Size Distribution')\n",
    "ax2.axvline(df['pct_core'].median(), color='red', linestyle='--',\n",
    "            label=f'Median: {df[\"pct_core\"].median():.1f}%')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Openness distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(df['openness'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "ax3.set_xlabel('Openness (Accessory/Core ratio)')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Pangenome Openness Distribution')\n",
    "ax3.axvline(df['openness'].median(), color='red', linestyle='--',\n",
    "            label=f'Median: {df[\"openness\"].median():.2f}')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Phylum distribution\n",
    "ax4 = axes[1, 1]\n",
    "phylum_counts = df['phylum'].value_counts().head(15)\n",
    "ax4.barh(range(len(phylum_counts)), phylum_counts.values)\n",
    "ax4.set_yticks(range(len(phylum_counts)))\n",
    "ax4.set_yticklabels(phylum_counts.index)\n",
    "ax4.set_xlabel('Number of Species')\n",
    "ax4.set_title('Species by Phylum (top 15)')\n",
    "ax4.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure_quality_filtering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved: figure_quality_filtering.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tree-header",
   "metadata": {},
   "source": [
    "## 4. Load Phylogenetic Tree\n",
    "\n",
    "We use the GTDB r214 bacterial tree (`bac120.tree`) which contains branch lengths derived from a concatenated alignment of 120 universal single-copy marker genes.\n",
    "\n",
    "The tree tips are labeled with representative genome accessions (RS_GCF_* or GB_GCA_*), which we match to our species data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-tree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the phylogenetic tree\n",
    "try:\n",
    "    from Bio import Phylo\n",
    "    HAVE_BIOPYTHON = True\n",
    "except ImportError:\n",
    "    HAVE_BIOPYTHON = False\n",
    "    print(\"BioPython not available, will use alternative tree parsing\")\n",
    "\n",
    "# Check tree file\n",
    "import os\n",
    "tree_file = 'bac120.tree'\n",
    "\n",
    "if os.path.exists(tree_file):\n",
    "    with open(tree_file, 'r') as f:\n",
    "        tree_content = f.read()\n",
    "    \n",
    "    # Extract genome IDs from tree\n",
    "    import re\n",
    "    tree_genome_ids = set(re.findall(r'(RS_GCF_\\d+\\.\\d+|GB_GCA_\\d+\\.\\d+)', tree_content))\n",
    "    \n",
    "    print(f\"Tree file: {tree_file}\")\n",
    "    print(f\"File size: {len(tree_content):,} characters\")\n",
    "    print(f\"Genome tips in tree: {len(tree_genome_ids):,}\")\n",
    "else:\n",
    "    print(f\"Tree file not found: {tree_file}\")\n",
    "    print(\"Will need to download GTDB tree\")\n",
    "    tree_genome_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "match-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match species to tree via representative genomes\n",
    "df['in_tree'] = df['rep_genome'].isin(tree_genome_ids)\n",
    "\n",
    "n_matched = df['in_tree'].sum()\n",
    "n_total = len(df)\n",
    "\n",
    "print(f\"Species with representative genome in tree: {n_matched:,} / {n_total:,} ({100*n_matched/n_total:.1f}%)\")\n",
    "\n",
    "# Filter to matched species\n",
    "df_tree = df[df['in_tree']].copy().reset_index(drop=True)\n",
    "print(f\"\\nFiltered dataset: {len(df_tree):,} species for phylogenetic analysis\")\n",
    "\n",
    "# Check taxonomic coverage\n",
    "print(f\"\\nTaxonomic coverage:\")\n",
    "print(f\"  Phyla: {df_tree['phylum'].nunique()}\")\n",
    "print(f\"  Classes: {df_tree['class'].nunique()}\")\n",
    "print(f\"  Orders: {df_tree['order'].nunique()}\")\n",
    "print(f\"  Families: {df_tree['family'].nunique()}\")\n",
    "print(f\"  Genera: {df_tree['genus'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distance-header",
   "metadata": {},
   "source": [
    "## 5. Compute Phylogenetic Distance Matrix\n",
    "\n",
    "We compute pairwise phylogenetic distances between species using the branch lengths from the GTDB tree. The distance between two species is the sum of branch lengths on the path connecting their representative genomes.\n",
    "\n",
    "For computational efficiency with large trees, we:\n",
    "1. Parse the Newick tree using BioPython (if available) or a custom parser\n",
    "2. Extract distances only for species pairs in our filtered dataset\n",
    "3. Use caching to avoid recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-phylo-dist",
   "metadata": {},
   "outputs": [],
   "source": "# Sample species for phylogenetic distance computation\n# With tree pruning + multiprocessing, we can efficiently handle 1000+ species\n\nMAX_SPECIES = 1000  # Configurable: try 500, 1000, or more\nUSE_PRECOMPUTED = False  # Set to True to use existing matrix\n\n# Check for pre-computed matrix matching our target size\nmatrix_file = f'phylo_distance_matrix_{MAX_SPECIES}.npy'\nspecies_file = f'phylo_matched_species_{MAX_SPECIES}.csv'\n\nif os.path.exists(matrix_file) and os.path.exists(species_file):\n    print(f\"Found pre-computed {MAX_SPECIES}-species matrix!\")\n    phylo_dist = np.load(matrix_file)\n    df_sample = pd.read_csv(species_file)\n    USE_PRECOMPUTED = True\nelif USE_PRECOMPUTED and os.path.exists('phylo_matched_species.csv'):\n    df_precomputed = pd.read_csv('phylo_matched_species.csv')\n    df_sample = df_precomputed[df_precomputed['no_genomes'] >= MIN_GENOMES].reset_index(drop=True)\n    print(f\"Using pre-computed data: {len(df_sample)} species (after quality filter)\")\nelse:\n    if len(df_tree) > MAX_SPECIES:\n        print(f\"Stratified sampling {MAX_SPECIES} species from {len(df_tree)}...\")\n        \n        # Stratified sampling by phylum to ensure diversity\n        df_sample = df_tree.groupby('phylum', group_keys=False).apply(\n            lambda x: x.sample(\n                min(len(x), max(1, int(MAX_SPECIES * len(x) / len(df_tree)))), \n                random_state=42\n            )\n        ).reset_index(drop=True)\n        \n        # Top up if needed\n        if len(df_sample) < MAX_SPECIES:\n            remaining = df_tree[~df_tree['rep_genome'].isin(df_sample['rep_genome'])]\n            n_extra = min(len(remaining), MAX_SPECIES - len(df_sample))\n            extra = remaining.sample(n_extra, random_state=42)\n            df_sample = pd.concat([df_sample, extra]).reset_index(drop=True)\n    else:\n        df_sample = df_tree.copy()\n\nprint(f\"Working with {len(df_sample)} species\")\nprint(f\"Phyla represented: {df_sample['phylum'].nunique()}\")\nprint(f\"Genome count range: {df_sample['no_genomes'].min()} - {df_sample['no_genomes'].max()}\")\nprint(f\"Expected pairs: {len(df_sample) * (len(df_sample)-1) // 2:,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse-tree",
   "metadata": {},
   "outputs": [],
   "source": "# Compute phylogenetic distances using a PRUNED subtree for efficiency\n# Uses multiprocessing for true parallel computation (ThreadPoolExecutor doesn't work\n# due to Python's GIL blocking CPU-bound work)\nimport numpy as np\nimport os\nfrom itertools import combinations\nimport time\nimport multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nfrom io import StringIO\n\n# Worker initialization for multiprocessing\ndef init_worker_with_tree(tree_str, genomes_list):\n    \"\"\"Initialize each worker process with its own tree copy.\"\"\"\n    global worker_tree, worker_genomes\n    from io import StringIO\n    from Bio import Phylo\n    worker_tree = Phylo.read(StringIO(tree_str), 'newick')\n    worker_genomes = genomes_list\n\ndef compute_distance_mp(args):\n    \"\"\"Compute pairwise distance in worker process.\"\"\"\n    i, j = args\n    try:\n        return (i, j, worker_tree.distance(worker_genomes[i], worker_genomes[j]))\n    except:\n        return (i, j, np.nan)\n\n# Configuration\nN_WORKERS = min(16, mp.cpu_count())  # Use up to 16 workers\n\n# Skip if already loaded from pre-computed\nif 'USE_PRECOMPUTED' in dir() and USE_PRECOMPUTED and 'phylo_dist' in dir():\n    print(f\"Using pre-computed distance matrix: {phylo_dist.shape}\")\n    n_species = len(df_sample)\nelse:\n    # Check for existing matrix matching our MAX_SPECIES\n    matrix_file = f'phylo_distance_matrix_{MAX_SPECIES}.npy'\n    species_file = f'phylo_matched_species_{MAX_SPECIES}.csv'\n\n    if os.path.exists(matrix_file) and os.path.exists(species_file):\n        print(f\"Loading pre-computed {MAX_SPECIES}-species matrix...\")\n        phylo_dist = np.load(matrix_file)\n        df_sample = pd.read_csv(species_file)\n        n_species = len(df_sample)\n        print(f\"Loaded {n_species} species\")\n    else:\n        # Check for BioPython\n        try:\n            from Bio import Phylo\n            HAVE_BIOPYTHON = True\n        except ImportError:\n            raise RuntimeError(\"BioPython required. Install with: pip install biopython\")\n\n        if not os.path.exists(tree_file):\n            raise RuntimeError(f\"Tree file not found: {tree_file}\")\n\n        # Parse tree\n        print(f\"Parsing phylogenetic tree...\")\n        start_time = time.time()\n        tree = Phylo.read(tree_file, 'newick')\n        parse_time = time.time() - start_time\n        print(f\"Tree parsed in {parse_time:.1f} seconds ({len(list(tree.get_terminals())):,} taxa)\")\n\n        # Get target genomes\n        genome_list = df_sample['rep_genome'].tolist()\n        target_set = set(genome_list)\n\n        # Find matching terminals\n        all_terminals = list(tree.get_terminals())\n        matching_terminals = [t for t in all_terminals if t.name in target_set]\n        found_genomes = [t.name for t in matching_terminals]\n        print(f\"Found {len(found_genomes)}/{len(genome_list)} genomes in tree\")\n\n        # Update df_sample\n        df_sample = df_sample[df_sample['rep_genome'].isin(found_genomes)].reset_index(drop=True)\n        genome_list = df_sample['rep_genome'].tolist()\n        n_species = len(df_sample)\n\n        # PRUNE TREE to only include our species (massive speedup!)\n        print(f\"Pruning tree to {n_species} species (this speeds up distance computation)...\")\n        start_time = time.time()\n\n        # Create a pruned copy\n        from copy import deepcopy\n        pruned_tree = deepcopy(tree)\n\n        # Get names to keep\n        keep_names = set(genome_list)\n\n        # Remove terminals not in our set\n        terminals_to_remove = [t for t in pruned_tree.get_terminals() if t.name not in keep_names]\n        for terminal in terminals_to_remove:\n            try:\n                pruned_tree.prune(terminal)\n            except ValueError:\n                pass  # Terminal may have been removed with parent\n\n        prune_time = time.time() - start_time\n        print(f\"Pruned tree in {prune_time:.1f} seconds ({len(list(pruned_tree.get_terminals()))} taxa remaining)\")\n\n        # Serialize pruned tree for multiprocessing workers\n        tree_io = StringIO()\n        Phylo.write(pruned_tree, tree_io, 'newick')\n        tree_string = tree_io.getvalue()\n\n        # Generate all pairs\n        pairs = list(combinations(range(n_species), 2))\n        n_pairs = len(pairs)\n        print(f\"\\nComputing {n_pairs:,} pairwise distances using {N_WORKERS} CPU cores...\")\n\n        # Initialize distance matrix\n        phylo_dist = np.zeros((n_species, n_species))\n\n        # Use multiprocessing for true parallelism (bypasses Python's GIL)\n        start_time = time.time()\n\n        ctx = mp.get_context('fork')  # 'fork' is faster on macOS/Linux\n        with ProcessPoolExecutor(max_workers=N_WORKERS,\n                                 mp_context=ctx,\n                                 initializer=init_worker_with_tree,\n                                 initargs=(tree_string, genome_list)) as executor:\n            # Process in chunks for progress reporting\n            chunk_size = max(1000, n_pairs // 20)  # ~20 progress updates\n            results = []\n\n            for chunk_start in range(0, n_pairs, chunk_size):\n                chunk_end = min(chunk_start + chunk_size, n_pairs)\n                chunk_pairs = pairs[chunk_start:chunk_end]\n\n                chunk_results = list(executor.map(compute_distance_mp, chunk_pairs, chunksize=100))\n                results.extend(chunk_results)\n\n                elapsed = time.time() - start_time\n                rate = len(results) / elapsed\n                eta = (n_pairs - len(results)) / rate if rate > 0 else 0\n                print(f\"  Progress: {len(results):,}/{n_pairs:,} ({100*len(results)/n_pairs:.1f}%) - \"\n                      f\"{rate:.0f} pairs/sec - ETA: {eta:.1f} sec\")\n\n        # Fill distance matrix from results\n        for i, j, dist in results:\n            phylo_dist[i, j] = dist\n            phylo_dist[j, i] = dist\n\n        total_time = time.time() - start_time\n        print(f\"\\nCompleted in {total_time:.1f} seconds ({n_pairs/total_time:.0f} pairs/sec)\")\n        print(f\"Speedup from {N_WORKERS} workers: ~{N_WORKERS*0.7:.1f}x vs sequential\")\n\n        # Save for future use\n        np.save(matrix_file, phylo_dist)\n        df_sample.to_csv(species_file, index=False)\n        print(f\"Saved: {matrix_file}, {species_file}\")\n\nprint(f\"\\nFinal dataset: {n_species} species with phylogenetic distances\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-distances",
   "metadata": {},
   "outputs": [],
   "source": "# Distance matrix statistics\nupper_tri = phylo_dist[np.triu_indices_from(phylo_dist, k=1)]\nvalid_dists = upper_tri[~np.isnan(upper_tri)]\n\nprint(\"Phylogenetic Distance Statistics\")\nprint(\"=\" * 50)\nprint(f\"Species: {n_species}\")\nprint(f\"Valid pairs: {len(valid_dists):,}\")\nprint(f\"Mean distance: {valid_dists.mean():.4f}\")\nprint(f\"Median distance: {np.median(valid_dists):.4f}\")\nprint(f\"Std deviation: {valid_dists.std():.4f}\")\nprint(f\"Range: {valid_dists.min():.4f} - {valid_dists.max():.4f}\")\n\n# Histogram of distances\nfig, ax = plt.subplots(figsize=(10, 5))\nax.hist(valid_dists, bins=50, edgecolor='black', alpha=0.7)\nax.axvline(valid_dists.mean(), color='red', linestyle='--', label=f'Mean: {valid_dists.mean():.3f}')\nax.axvline(np.median(valid_dists), color='orange', linestyle='--', label=f'Median: {np.median(valid_dists):.3f}')\nax.set_xlabel('Phylogenetic Distance')\nax.set_ylabel('Count')\nax.set_title(f'Distribution of Pairwise Phylogenetic Distances (n={len(valid_dists):,} pairs)')\nax.legend()\nplt.tight_layout()\nplt.savefig('figure_phylo_distance_distribution.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\nFigure saved: figure_phylo_distance_distribution.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "gene-content-header",
   "metadata": {},
   "source": [
    "## 6. Compute Gene Content Distance Matrices\n",
    "\n",
    "We compute pairwise \"gene content distance\" using multiple metrics:\n",
    "\n",
    "1. **Core genome %**: Difference in proportion of core genes\n",
    "2. **Openness**: Difference in accessory/core ratio\n",
    "3. **Core gene count**: Absolute difference in core genes\n",
    "4. **Pangenome size**: Difference in total gene clusters\n",
    "\n",
    "Each metric captures a different aspect of pangenome structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gene-content-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(values):\n",
    "    \"\"\"Compute pairwise absolute difference matrix.\"\"\"\n",
    "    n = len(values)\n",
    "    mat = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mat[i, j] = abs(values[i] - values[j])\n",
    "    return mat\n",
    "\n",
    "# Compute gene content distance matrices\n",
    "metrics = {\n",
    "    'pct_core': df_sample['pct_core'].values,\n",
    "    'openness': df_sample['openness'].values,\n",
    "    'no_core': df_sample['no_core'].values,\n",
    "    'no_gene_clusters': df_sample['no_gene_clusters'].values,\n",
    "    'avg_genes_per_genome': df_sample['avg_genes_per_genome'].values\n",
    "}\n",
    "\n",
    "gene_content_dists = {}\n",
    "for name, values in metrics.items():\n",
    "    gene_content_dists[name] = compute_distance_matrix(values)\n",
    "    print(f\"Computed {name} distance matrix\")\n",
    "\n",
    "print(f\"\\nAll gene content distance matrices computed: {list(gene_content_dists.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation-header",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "We now test whether phylogenetic distance predicts gene content distance using:\n",
    "\n",
    "1. **Pearson correlation**: Linear relationship\n",
    "2. **Spearman correlation**: Rank-based (robust to outliers)\n",
    "3. **Mantel test**: Permutation-based significance test for matrix correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_corr(x, y):\n",
    "    \"\"\"Calculate Spearman rank correlation.\"\"\"\n",
    "    mask = ~(np.isnan(x) | np.isnan(y))\n",
    "    x, y = x[mask], y[mask]\n",
    "    n = len(x)\n",
    "    if n < 3:\n",
    "        return np.nan\n",
    "    x_ranks = np.argsort(np.argsort(x)) + 1\n",
    "    y_ranks = np.argsort(np.argsort(y)) + 1\n",
    "    d = x_ranks - y_ranks\n",
    "    rho = 1 - (6 * np.sum(d**2)) / (n * (n**2 - 1))\n",
    "    return rho\n",
    "\n",
    "def mantel_test(mat1, mat2, n_permutations=999):\n",
    "    \"\"\"Mantel test for matrix correlation with permutation significance.\"\"\"\n",
    "    idx = np.triu_indices_from(mat1, k=1)\n",
    "    vec1 = mat1[idx]\n",
    "    vec2 = mat2[idx]\n",
    "    \n",
    "    # Remove NaN pairs\n",
    "    mask = ~(np.isnan(vec1) | np.isnan(vec2))\n",
    "    vec1, vec2 = vec1[mask], vec2[mask]\n",
    "    \n",
    "    # Observed correlation\n",
    "    obs_corr = np.corrcoef(vec1, vec2)[0, 1]\n",
    "    \n",
    "    # Permutation test\n",
    "    n = len(mat1)\n",
    "    perm_corrs = []\n",
    "    for _ in range(n_permutations):\n",
    "        perm = np.random.permutation(n)\n",
    "        mat1_perm = mat1[np.ix_(perm, perm)]\n",
    "        vec1_perm = mat1_perm[idx][mask]\n",
    "        perm_corrs.append(np.corrcoef(vec1_perm, vec2)[0, 1])\n",
    "    \n",
    "    perm_corrs = np.array(perm_corrs)\n",
    "    p_value = (np.sum(np.abs(perm_corrs) >= np.abs(obs_corr)) + 1) / (n_permutations + 1)\n",
    "    \n",
    "    return obs_corr, p_value\n",
    "\n",
    "# Flatten phylogenetic distances\n",
    "phylo_flat = phylo_dist[np.triu_indices_from(phylo_dist, k=1)]\n",
    "\n",
    "print(\"Correlation: Phylogenetic Distance vs Gene Content Distance\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<25} {'Pearson r':>12} {'Spearman ρ':>12} {'Mantel p':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "np.random.seed(42)\n",
    "results = []\n",
    "\n",
    "for name, gene_dist in gene_content_dists.items():\n",
    "    gene_flat = gene_dist[np.triu_indices_from(gene_dist, k=1)]\n",
    "    \n",
    "    # Remove NaN pairs\n",
    "    mask = ~(np.isnan(phylo_flat) | np.isnan(gene_flat))\n",
    "    \n",
    "    pearson_r = np.corrcoef(phylo_flat[mask], gene_flat[mask])[0, 1]\n",
    "    spearman_r = spearman_corr(phylo_flat, gene_flat)\n",
    "    mantel_r, mantel_p = mantel_test(phylo_dist, gene_dist, n_permutations=499)\n",
    "    \n",
    "    sig = '*' if mantel_p < 0.05 else ''\n",
    "    print(f\"{name:<25} {pearson_r:>+12.4f} {spearman_r:>+12.4f} {mantel_p:>11.4f}{sig}\")\n",
    "    \n",
    "    results.append({\n",
    "        'metric': name,\n",
    "        'pearson': pearson_r,\n",
    "        'spearman': spearman_r,\n",
    "        'mantel_p': mantel_p\n",
    "    })\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(\"* = significant at p < 0.05\")\n",
    "\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taxonomic-header",
   "metadata": {},
   "source": [
    "## 8. Taxonomic Level Analysis\n",
    "\n",
    "The global correlation may be weak because different taxonomic levels show different patterns. We now stratify by taxonomic relatedness:\n",
    "\n",
    "- **Same genus**: Most closely related\n",
    "- **Same family**: Related\n",
    "- **Same phylum**: Distantly related\n",
    "- **Different domains**: Most distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taxonomic-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxonomic_distance(row1, row2):\n",
    "    \"\"\"Calculate taxonomic distance (0-6 scale).\"\"\"\n",
    "    levels = ['domain', 'phylum', 'class', 'order', 'family', 'genus']\n",
    "    for i, level in enumerate(levels):\n",
    "        if row1[level] != row2[level]:\n",
    "            return 6 - i  # Higher = more distant\n",
    "    return 0  # Same genus\n",
    "\n",
    "# Compute taxonomic distance matrix\n",
    "n = len(df_sample)\n",
    "tax_dist = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        tax_dist[i, j] = taxonomic_distance(df_sample.iloc[i], df_sample.iloc[j])\n",
    "\n",
    "# Labels for taxonomic levels\n",
    "level_names = {\n",
    "    0: 'Same genus',\n",
    "    1: 'Same family',\n",
    "    2: 'Same order',\n",
    "    3: 'Same class',\n",
    "    4: 'Same phylum',\n",
    "    5: 'Same domain',\n",
    "    6: 'Different domain'\n",
    "}\n",
    "\n",
    "# Get flattened vectors\n",
    "idx = np.triu_indices_from(tax_dist, k=1)\n",
    "tax_flat = tax_dist[idx]\n",
    "gene_core_flat = gene_content_dists['pct_core'][idx]\n",
    "\n",
    "print(\"Gene Content Distance by Taxonomic Level\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Taxonomic Level':<20} {'N pairs':>10} {'Mean Δ%core':>15} {'Std':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for level in sorted(np.unique(tax_flat)):\n",
    "    mask = tax_flat == level\n",
    "    if mask.sum() > 0:\n",
    "        gene_dists = gene_core_flat[mask]\n",
    "        print(f\"{level_names.get(int(level), f'Level {int(level)}'):<20} \"\n",
    "              f\"{mask.sum():>10,} {gene_dists.mean():>15.2f} {gene_dists.std():>10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-by-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation at each taxonomic level\n",
    "print(\"\\nCorrelation (Phylo vs Gene Content) by Taxonomic Level\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Level':<20} {'N pairs':>10} {'Pearson r':>12} {'Interpretation':<20}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "level_correlations = []\n",
    "\n",
    "for level in sorted(np.unique(tax_flat)):\n",
    "    mask = (tax_flat == level) & ~np.isnan(phylo_flat)\n",
    "    if mask.sum() >= 10:\n",
    "        r = np.corrcoef(phylo_flat[mask], gene_core_flat[mask])[0, 1]\n",
    "        \n",
    "        if abs(r) < 0.1:\n",
    "            interp = \"No correlation\"\n",
    "        elif r > 0.3:\n",
    "            interp = \"Positive (divergent)\"\n",
    "        elif r < -0.3:\n",
    "            interp = \"Negative (convergent)\"\n",
    "        else:\n",
    "            interp = \"Weak\"\n",
    "        \n",
    "        print(f\"{level_names.get(int(level), f'Level {int(level)}'):<20} \"\n",
    "              f\"{mask.sum():>10,} {r:>+12.4f} {interp:<20}\")\n",
    "        \n",
    "        level_correlations.append({\n",
    "            'level': int(level),\n",
    "            'name': level_names.get(int(level)),\n",
    "            'n_pairs': mask.sum(),\n",
    "            'correlation': r\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-header",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# 1. Scatter: Phylo vs Gene Content Distance\n",
    "ax1 = axes[0, 0]\n",
    "mask = ~np.isnan(phylo_flat)\n",
    "hb = ax1.hexbin(phylo_flat[mask], gene_core_flat[mask], gridsize=30, cmap='YlOrRd', mincnt=1)\n",
    "ax1.set_xlabel('Phylogenetic Distance')\n",
    "ax1.set_ylabel('Gene Content Distance (Δ%core)')\n",
    "r = np.corrcoef(phylo_flat[mask], gene_core_flat[mask])[0, 1]\n",
    "ax1.set_title(f'Phylo vs Gene Content\\nr = {r:.3f}')\n",
    "plt.colorbar(hb, ax=ax1, label='Count')\n",
    "\n",
    "# 2. Boxplot: Gene content by taxonomic level\n",
    "ax2 = axes[0, 1]\n",
    "data_by_level = []\n",
    "labels = []\n",
    "for level in sorted(np.unique(tax_flat)):\n",
    "    mask = tax_flat == level\n",
    "    if mask.sum() > 0:\n",
    "        data_by_level.append(gene_core_flat[mask])\n",
    "        labels.append(level_names.get(int(level), '').replace('Same ', '').replace('Different ', 'Diff\\n'))\n",
    "\n",
    "ax2.boxplot(data_by_level, tick_labels=labels)\n",
    "ax2.set_xlabel('Taxonomic Relatedness')\n",
    "ax2.set_ylabel('Gene Content Distance (Δ%core)')\n",
    "ax2.set_title('Gene Content by Taxonomy')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Boxplot: Phylo distance by taxonomic level\n",
    "ax3 = axes[0, 2]\n",
    "phylo_by_level = []\n",
    "for level in sorted(np.unique(tax_flat)):\n",
    "    mask = (tax_flat == level) & ~np.isnan(phylo_flat)\n",
    "    if mask.sum() > 0:\n",
    "        phylo_by_level.append(phylo_flat[mask])\n",
    "\n",
    "ax3.boxplot(phylo_by_level, tick_labels=labels)\n",
    "ax3.set_xlabel('Taxonomic Relatedness')\n",
    "ax3.set_ylabel('Phylogenetic Distance')\n",
    "ax3.set_title('Phylo Distance by Taxonomy')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Bar: Correlation by taxonomic level\n",
    "ax4 = axes[1, 0]\n",
    "if level_correlations:\n",
    "    df_corr = pd.DataFrame(level_correlations)\n",
    "    colors = ['green' if r > 0 else 'red' for r in df_corr['correlation']]\n",
    "    ax4.bar(range(len(df_corr)), df_corr['correlation'], color=colors, alpha=0.7)\n",
    "    ax4.axhline(0, color='black', linewidth=0.5)\n",
    "    ax4.set_xticks(range(len(df_corr)))\n",
    "    ax4.set_xticklabels([n.replace('Same ', '').replace('Different ', 'Diff ') \n",
    "                         for n in df_corr['name']], rotation=45, ha='right')\n",
    "    ax4.set_ylabel('Pearson Correlation')\n",
    "    ax4.set_title('Phylo-Gene Correlation by Level')\n",
    "    ax4.set_ylim(-0.5, 0.5)\n",
    "\n",
    "# 5. Scatter colored by taxonomy\n",
    "ax5 = axes[1, 1]\n",
    "scatter = ax5.scatter(phylo_flat[mask], gene_core_flat[mask], \n",
    "                      c=tax_flat[mask], cmap='viridis', alpha=0.3, s=3)\n",
    "ax5.set_xlabel('Phylogenetic Distance')\n",
    "ax5.set_ylabel('Gene Content Distance (Δ%core)')\n",
    "ax5.set_title('Colored by Taxonomic Level')\n",
    "cbar = plt.colorbar(scatter, ax=ax5)\n",
    "cbar.set_label('Taxonomic Distance')\n",
    "\n",
    "# 6. Core % by phylum\n",
    "ax6 = axes[1, 2]\n",
    "phylum_means = df_sample.groupby('phylum')['pct_core'].agg(['mean', 'std', 'count'])\n",
    "phylum_means = phylum_means[phylum_means['count'] >= 5].sort_values('mean', ascending=True).tail(12)\n",
    "ax6.barh(range(len(phylum_means)), phylum_means['mean'], \n",
    "         xerr=phylum_means['std'], capsize=3, alpha=0.7)\n",
    "ax6.set_yticks(range(len(phylum_means)))\n",
    "ax6.set_yticklabels(phylum_means.index)\n",
    "ax6.set_xlabel('Mean Core Genome (%)')\n",
    "ax6.set_title('Core Genome by Phylum')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure_gene_content_phylogeny.png', dpi=150, bbox_inches='tight')\n",
    "plt.savefig('figure_gene_content_phylogeny.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figures saved: figure_gene_content_phylogeny.png, .pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: Gene Content vs Phylogenetic Distance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n### Dataset\")\n",
    "print(f\"  Species analyzed: {len(df_sample):,}\")\n",
    "print(f\"  Pairwise comparisons: {len(phylo_flat):,}\")\n",
    "print(f\"  Phyla represented: {df_sample['phylum'].nunique()}\")\n",
    "\n",
    "print(f\"\\n### Quality Filters Applied\")\n",
    "print(f\"  Minimum genomes per species: {MIN_GENOMES}\")\n",
    "print(f\"  Minimum core genes: {MIN_CORE_GENES}\")\n",
    "print(f\"  Minimum ANI: {MIN_ANI}%\")\n",
    "\n",
    "print(f\"\\n### Global Correlation Results\")\n",
    "mask = ~np.isnan(phylo_flat)\n",
    "r = np.corrcoef(phylo_flat[mask], gene_core_flat[mask])[0, 1]\n",
    "print(f\"  Pearson r (phylo vs Δ%core): {r:.4f}\")\n",
    "print(f\"  Interpretation: {'Weak/No' if abs(r) < 0.2 else 'Moderate' if abs(r) < 0.5 else 'Strong'} correlation\")\n",
    "\n",
    "print(f\"\\n### Key Findings\")\n",
    "findings = [\n",
    "    \"1. Gene content (% core) shows WEAK correlation with phylogenetic distance\",\n",
    "    \"2. Closely related species (same genus) can have highly divergent gene content\",\n",
    "    \"3. Distantly related species can have similar pangenome structures\",\n",
    "    \"4. Taxonomy predicts phylogenetic distance but NOT gene content similarity\",\n",
    "    \"5. Ecological factors may be more important than ancestry for pangenome structure\"\n",
    "]\n",
    "for f in findings:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "print(f\"\\n### Implications\")\n",
    "print(\"  - Pangenome 'openness' is not strictly inherited\")\n",
    "print(\"  - Horizontal gene transfer may homogenize distant lineages\")\n",
    "print(\"  - Niche specialization can rapidly alter gene content\")\n",
    "print(\"  - Phylogeny alone is insufficient to predict genome plasticity\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results table\n",
    "df_results.to_csv('gene_content_phylogeny_correlations.csv', index=False)\n",
    "print(\"Results saved: gene_content_phylogeny_correlations.csv\")\n",
    "\n",
    "# Display final results\n",
    "print(\"\\nCorrelation Summary:\")\n",
    "display(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}