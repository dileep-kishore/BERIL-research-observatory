---
reviewer: BERIL Automated Review
date: 2026-02-16
project: enigma_contamination_functional_potential
---

# Review: Contamination Gradient vs Functional Potential in ENIGMA Communities

## Summary
This project is strong overall: the research question is clear, the workflow from extraction to modeling is coherent, and reproducibility is substantially above baseline (saved notebook outputs, explicit run order, runtimes, and generated artifacts). The analysis is appropriately cautious in interpretation and clearly separates confirmatory from exploratory tests. The main remaining gaps are interpretability and inferential sharpness rather than implementation correctness: confirmatory visual presentation is weaker than exploratory presentation, genus-level taxonomic bridging still dominates uncertainty, and the report could make model-family multiplicity and power tradeoffs even more explicit in the main narrative.

## Methodology
The question and hypothesis are specific and testable in `README.md` and `RESEARCH_PLAN.md`, and notebook sequencing is logical:
- `notebooks/01_enigma_extraction_qc.ipynb`: overlap extraction and QC export
- `notebooks/02_taxonomy_bridge_functional_features.ipynb`: taxon bridge and feature generation
- `notebooks/03_contamination_functional_models.ipynb`: contamination index construction, modeling, sensitivity analyses, and figure generation

Data sources are clearly identified (ENIGMA `ddt/sdt` tables plus pangenome taxonomy/annotation tables), and implementation aligns with known pitfalls from `docs/pitfalls.md`:
- explicit numeric casting for string-prone fields,
- Spark-side heavy work before local aggregation,
- correct annotation join key (`gene_cluster.gene_cluster_id` to `eggnog_mapper_annotations.query_name`),
- independent strict/relaxed/species-proxy feature construction.

Reproducibility is strong:
- `README.md` has a concrete `## Reproduction` section with Spark/local separation and expected runtimes,
- `requirements.txt` is present,
- all three notebooks contain saved outputs (NB03 has two no-output placeholder cells only),
- expected artifacts exist (10 data TSVs, 3 figures).

## Code Quality
Code organization and defensive checks are good. Notebooks are structured setup -> transforms -> modeling -> exports, with explicit status handling (`insufficient_samples`, `constant_feature`) and multiple robustness layers (fraction-aware, high-coverage subset, contamination-index sensitivity, coverage deciles). Global BH-FDR is implemented across all discovered p-value columns containing `_p`, which avoids missing non-standard names.

No clear executable bug was found from file inspection. Remaining technical risks are mostly methodological:
- genus normalization via string heuristics can still collapse biologically distinct labels in edge cases,
- species-proxy mode is coverage-limited by design (very low mapped abundance in many samples),
- broad COG-category proxies may under-resolve pathway-specific stress biology.

## Findings Assessment
The reportâ€™s core conclusions are supported by generated tables and figures:
- confirmatory defense endpoint remains null in primary genus-level modes with bootstrap CIs and FDR,
- exploratory positive defense associations appear in coverage-aware adjusted models,
- within-fraction monotonic checks are largely null,
- contamination-index variant sensitivity does not reverse confirmatory conclusions,
- species-proxy mode loses substantial coverage and does not materially strengthen inference.

Limitations are explicitly acknowledged and appropriately constrain interpretation. The write-up avoids over-claiming causality.

## Suggestions
1. Prioritize confirmatory communication in the visuals: add a dedicated confirmatory figure/table (`site_defense_score` vs contamination, strict/relaxed) so the main claim is directly visualized rather than inferred from model tables.
2. Surface multiplicity and effective sample size earlier in `REPORT.md`: move a compact model-family/sample-count summary near Key Findings to reduce risk of over-reading exploratory families.
3. Add a brief sensitivity note on genus normalization quality (for example, top ambiguous or suspicious mappings) to quantify potential bridge misassignment risk.
4. Extend uncertainty reporting from key coefficients to a compact per-family uncertainty summary table (effect, CI, q-value, n) for faster cross-model comparison.
5. If/when ENIGMA species/strain resolution becomes available, rerun the same pipeline at higher taxonomic resolution before adding additional model complexity.

## Review Metadata
- **Reviewer**: BERIL Automated Review
- **Date**: 2026-02-16
- **Scope**: README.md, 3 notebooks, 10 data files, 3 figures
- **Note**: This review was generated by an AI system. It should be treated as advisory input, not a definitive assessment.
