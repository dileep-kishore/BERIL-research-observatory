---
reviewer: BERIL Automated Review
date: 2026-02-15
project: enigma_contamination_functional_potential
---

# Review: Contamination Gradient vs Functional Potential in ENIGMA Communities

## Summary
This project is well-structured and reproducible at a practical level: the three-notebook pipeline executes end-to-end, outputs are persisted in `data/`, and the report is aligned with the observed statistical signal (no strong association). The strongest aspects are disciplined Spark-first extraction and explicit acknowledgment of mapping/aggregation limitations. The main improvements needed are documentation consistency and a small modeling robustness gap around constant-feature handling.

## Methodology
The research question in `projects/enigma_contamination_functional_potential/README.md` is clear and testable. The approach in `projects/enigma_contamination_functional_potential/RESEARCH_PLAN.md` is coherent: ENIGMA extraction, taxonomy bridge to pangenome, feature construction, and contamination-association testing. Data sources are identified concretely in the plan and implemented in notebooks. Reproducibility is mostly strong because executed notebook outputs are saved and derived TSV artifacts are committed.

A key methodological caveat is the genus-level bridge strategy in `projects/enigma_contamination_functional_potential/notebooks/02_taxonomy_bridge_functional_features.ipynb`, which can blur species-level functional differences; this is acknowledged in the report and is acceptable for a first-pass synthesis.

## Code Quality
Notebook organization is logical and follows setup → extraction/transform → model/report flow. `projects/enigma_contamination_functional_potential/notebooks/01_enigma_extraction_qc.ipynb` uses Spark aggregation before collecting to pandas, which correctly avoids the driver result-size failure mode documented in BERDL pitfalls. SQL join keys for annotation linkage in `projects/enigma_contamination_functional_potential/notebooks/02_taxonomy_bridge_functional_features.ipynb` are consistent with documented pangenome join guidance.

One robustness issue remains in `projects/enigma_contamination_functional_potential/notebooks/03_contamination_functional_models.ipynb`: when a feature has near-zero variance (as seen for mobilome score), Spearman/linear outputs can become NaN or degenerate, and the resulting row appears with partial/blank stats in `projects/enigma_contamination_functional_potential/data/model_results.tsv`. The notebook should explicitly detect and label constant or quasi-constant outcomes before statistical testing.

## Findings Assessment
Conclusions in `projects/enigma_contamination_functional_potential/REPORT.md` are appropriately conservative and supported by the reported metrics in `projects/enigma_contamination_functional_potential/data/model_results.tsv` (e.g., stress/defense rho around 0.059 with non-significant p-values). Limitations are clearly discussed, especially resolution and mapping ambiguity. The single figure in `projects/enigma_contamination_functional_potential/figures/contamination_vs_functional_score.png` supports the central conclusion but does not yet provide a fuller diagnostic view (e.g., feature distribution or mapping-confidence sensitivity visuals).

## Suggestions
1. Add explicit constant-feature guards in `projects/enigma_contamination_functional_potential/notebooks/03_contamination_functional_models.ipynb` and write sentinel labels (e.g., `status=constant_feature`) instead of emitting partial rows in `projects/enigma_contamination_functional_potential/data/model_results.tsv`.
2. Update `projects/enigma_contamination_functional_potential/README.md` for consistency: the Quick Links line still says report is “to be generated,” and the Reproduction section remains placeholder text despite executed notebooks and committed outputs.
3. Add a minimal `projects/enigma_contamination_functional_potential/references.md` with citations for ENIGMA context and related BERIL analyses to align with submission advisory expectations.
4. Add at least one diagnostic figure beyond the main scatter (for example, contamination-index distribution and/or mapping coverage summary from `taxon_bridge.tsv`) to strengthen interpretability.
5. Consider sensitivity analyses by mapping tier (strict vs relaxed bridge) and include side-by-side results in report tables to quantify mapping uncertainty impact.

## Review Metadata
- **Reviewer**: BERIL Automated Review
- **Date**: 2026-02-15
- **Scope**: README.md, 3 notebooks, 7 data files, 1 figure
- **Note**: This review was generated by an AI system. It should be treated as advisory input, not a definitive assessment.
