{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: GapMind Pathway Analysis\n",
    "\n",
    "**Goal**: Identify universally complete metabolic pathways in 48 Fitness Browser organisms\n",
    "\n",
    "**Research Question**: Which metabolic pathways are universally complete across bacteria with essential gene data?\n",
    "\n",
    "**Data sources**:\n",
    "- Essential gene families: `projects/essential_genome/` (48 FB organisms)\n",
    "- GapMind predictions: `kbase_ke_pangenome.gapmind_pathways` (305M predictions)\n",
    "- Genome metadata: `kbase_ke_pangenome.genome`\n",
    "\n",
    "**Approach**:\n",
    "1. Load FB organism list (48 organisms from essential_genome)\n",
    "2. Map FB organism names → pangenome genome_ids\n",
    "3. Extract GapMind predictions for those 48 genomes\n",
    "4. Identify universally complete pathways\n",
    "5. Characterize essential metabolic repertoire\n",
    "\n",
    "**Note**: This uses revised approach (v2) - pathway-level analysis instead of EC→reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Spark Connect\n",
    "from get_spark_session import get_spark_session\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = get_spark_session()\n",
    "print(f\"✅ Spark session created: version {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load FB Organism List\n",
    "\n",
    "Get the 48 organisms from essential_genome project. Need to extract organism names and map them to genome IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download essential families from lakehouse (or use cached)\n",
    "# This references data from essential_genome project (proper attribution)\n",
    "\n",
    "import os\n",
    "\n",
    "essential_families_file = Path(\"../data/essential_genome_families.tsv\")\n",
    "\n",
    "if not essential_families_file.exists():\n",
    "    print(\"Downloading essential families from lakehouse...\")\n",
    "    os.system(f\"\"\"\n",
    "        export https_proxy=http://127.0.0.1:8123 && \n",
    "        export no_proxy=localhost,127.0.0.1 && \n",
    "        mc cp berdl-minio/cdm-lake/tenant-general-warehouse/microbialdiscoveryforge/projects/essential_genome/data/essential_families.tsv {essential_families_file}\n",
    "    \"\"\")\n",
    "    print(f\"✅ Downloaded to {essential_families_file}\")\n",
    "else:\n",
    "    print(f\"✅ Using cached file: {essential_families_file}\")\n",
    "\n",
    "# Load\n",
    "families = pd.read_csv(essential_families_file, sep='\\t')\n",
    "print(f\"\\nLoaded {len(families):,} ortholog groups\")\n",
    "print(f\"Universally essential: {(families['essentiality_class'] == 'universally_essential').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract organism names from essential_organisms column\n",
    "# Example: \"BFirm;Burk376;Caulo;Cup4G11;...\"\n",
    "\n",
    "universal = families[families['essentiality_class'] == 'universally_essential']\n",
    "\n",
    "# Get organism list from first universal family\n",
    "organism_str = universal.iloc[0]['essential_organisms']\n",
    "fb_organisms = sorted(organism_str.split(';'))\n",
    "\n",
    "print(f\"FB organisms ({len(fb_organisms)}):\")\n",
    "for i, org in enumerate(fb_organisms, 1):\n",
    "    print(f\"{i:2d}. {org}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Map FB Names to Genome IDs\n",
    "\n",
    "FB organism names (e.g., \"Keio\", \"DvH\") need to map to pangenome genome_ids (e.g., \"GCF_000005845.2\").\n",
    "\n",
    "Strategy:\n",
    "1. Use known mappings from previous projects if available\n",
    "2. Otherwise, search genome table by taxonomy or NCBI IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mapping file exists from conservation_vs_fitness project\n",
    "link_file = Path(\"../../conservation_vs_fitness/data/fb_pangenome_link.tsv\")\n",
    "\n",
    "if link_file.exists():\n",
    "    print(f\"✅ Found FB-pangenome link file: {link_file}\")\n",
    "    fb_link = pd.read_csv(link_file, sep='\\t')\n",
    "    print(f\"   {len(fb_link):,} rows\")\n",
    "    print(f\"\\nColumns: {list(fb_link.columns)}\")\n",
    "    print(\"\\nSample:\")\n",
    "    print(fb_link.head())\n",
    "    \n",
    "    # Extract unique organism → genome_id mappings\n",
    "    if 'organism' in fb_link.columns and 'gtdb_species_clade_id' in fb_link.columns:\n",
    "        org_genome_map = fb_link[['organism', 'gtdb_species_clade_id']].drop_duplicates()\n",
    "        print(f\"\\nUnique organism mappings: {len(org_genome_map)}\")\n",
    "else:\n",
    "    print(\"⚠️  FB-pangenome link file not found\")\n",
    "    print(\"   Will need to create mapping manually\")\n",
    "    fb_link = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract GapMind Predictions for FB Organisms\n",
    "\n",
    "Query GapMind for the 48 FB organisms (or their representative genomes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, let's explore GapMind structure to understand how to link\n",
    "# We'll use genome_id patterns or species names\n",
    "\n",
    "print(\"Exploring GapMind genome_id patterns...\")\n",
    "genome_sample = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT genome_id\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways\n",
    "    LIMIT 20\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(\"Sample genome IDs in GapMind:\")\n",
    "print(genome_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pathway summary across all genomes to understand data structure\n",
    "print(\"Pathway completeness summary (amino acids):\")\n",
    "aa_summary = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        pathway,\n",
    "        COUNT(DISTINCT genome_id) as n_genomes,\n",
    "        SUM(CASE WHEN score_category = 'complete' THEN 1 ELSE 0 END) as n_complete,\n",
    "        SUM(CASE WHEN score_category = 'likely_complete' THEN 1 ELSE 0 END) as n_likely,\n",
    "        ROUND(100.0 * SUM(CASE WHEN score_category IN ('complete', 'likely_complete') THEN 1 ELSE 0 END) / COUNT(*), 1) as pct_present\n",
    "    FROM kbase_ke_pangenome.gapmind_pathways\n",
    "    WHERE metabolic_category = 'aa'\n",
    "    GROUP BY pathway\n",
    "    ORDER BY pct_present DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "print(aa_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identify Universally Complete Pathways\n",
    "\n",
    "Once we have the FB organism mappings, we'll:\n",
    "1. Filter GapMind to those 48 genomes\n",
    "2. Find pathways that are complete/likely_complete in ALL 48\n",
    "3. Characterize the minimal metabolic repertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for next step\n",
    "# Will need FB → genome_id mapping to proceed\n",
    "\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Complete FB organism → genome_id mapping\")\n",
    "print(\"2. Query GapMind for those specific genomes\")\n",
    "print(\"3. Identify universally complete pathways\")\n",
    "print(\"4. Create visualizations\")\n",
    "print(\"5. Compare to minimal genome studies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Progress\n",
    "\n",
    "Save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FB organism list\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "fb_org_file = data_dir / \"fb_organisms.txt\"\n",
    "with open(fb_org_file, 'w') as f:\n",
    "    for org in fb_organisms:\n",
    "        f.write(f\"{org}\\n\")\n",
    "\n",
    "print(f\"✅ Saved FB organism list: {fb_org_file}\")\n",
    "print(f\"   {len(fb_organisms)} organisms\")\n",
    "\n",
    "# Save pathway summary\n",
    "aa_summary.to_csv(data_dir / \"gapmind_aa_pathway_summary.tsv\", sep='\\t', index=False)\n",
    "print(f\"\\n✅ Saved pathway summary: gapmind_aa_pathway_summary.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "spark.stop()\n",
    "print(\"✅ Spark session closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Completed**:\n",
    "- ✅ Loaded 48 FB organism names from essential_genome project\n",
    "- ✅ Explored GapMind pathway structure\n",
    "- ✅ Analyzed amino acid pathway completeness across all genomes\n",
    "\n",
    "**Findings**:\n",
    "- GapMind has 80 pathways (18 amino acids + 62 carbon sources)\n",
    "- Pathway completeness varies: met > gln > asn > gly > thr\n",
    "- Need FB organism → genome_id mapping to proceed\n",
    "\n",
    "**Next Steps**:\n",
    "1. Create or find FB → genome_id mapping\n",
    "2. Extract GapMind predictions for 48 FB genomes\n",
    "3. Identify universally complete pathways\n",
    "4. Visualize essential metabolic repertoire\n",
    "5. Compare to JCVI-syn3.0 minimal genome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
