{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB02: Interactive Exploration — AlphaEarth Embeddings, Geography & Environment\n",
    "\n",
    "**Can run on JupyterHub or locally** after `pip install -r ../requirements.txt`.\n",
    "\n",
    "This notebook takes the extracted data from NB01 and performs interactive analysis with plotly visualizations. The goal is to characterize the AlphaEarth embedding space and understand what these 64-dimensional satellite-derived vectors actually capture.\n",
    "\n",
    "## Questions we're exploring\n",
    "\n",
    "1. **Coverage**: Which metadata attributes are available, and in what combinations?\n",
    "2. **Data quality**: Are the lat/lon coordinates trustworthy, or do some refer to institutions rather than sampling sites?\n",
    "3. **Environment harmonization**: Can we map 5,774 free-text isolation source values into meaningful categories?\n",
    "4. **Embedding structure**: What does the 64-dim space look like when projected to 2D? Do clusters correspond to environments?\n",
    "5. **Geography–embedding relationship**: Does geographic proximity predict embedding similarity?\n",
    "6. **Cluster–environment correspondence**: Do UMAP clusters map onto environment types?\n",
    "\n",
    "## Interactive figures\n",
    "\n",
    "All plotly figures in this notebook are **interactive** — hover for tooltips, click legend entries to toggle, use the toolbar to zoom/pan/select. Static PNGs are also saved to `../figures/` for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import DBSCAN\n",
    "import umap\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "FIG_DIR = '../figures'\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "EMB_COLS = [f'A{i:02d}' for i in range(64)]\n",
    "\n",
    "# Helper to save both PNG and interactive HTML\n",
    "def save_fig(fig, name):\n",
    "    \"\"\"Save a plotly figure as PNG and HTML.\"\"\"\n",
    "    fig.write_image(os.path.join(FIG_DIR, f'{name}.png'), scale=2)\n",
    "    fig.write_html(os.path.join(FIG_DIR, f'{name}.html'))\n",
    "    print(f'Saved figures/{name}.png + .html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from NB01\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, 'alphaearth_with_env.csv'))\n",
    "coverage = pd.read_csv(os.path.join(DATA_DIR, 'coverage_stats.csv'))\n",
    "attr_counts = pd.read_csv(os.path.join(DATA_DIR, 'ncbi_env_attribute_counts.csv'))\n",
    "iso_counts = pd.read_csv(os.path.join(DATA_DIR, 'isolation_source_raw_counts.csv'))\n",
    "\n",
    "print(f'Loaded {len(df):,} genomes with {len(df.columns)} columns')\n",
    "print(f'Unique isolation_source values: {len(iso_counts):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Coverage Overview\n",
    "\n",
    "Not all genomes have all metadata fields. Understanding the overlap between attributes is important for knowing which analyses are feasible and what biases might exist.\n",
    "\n",
    "We show two views:\n",
    "- A **bar chart** of per-attribute population rates\n",
    "- An **intersection chart** showing which combinations of attributes co-occur (UpSet-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cov = px.bar(\n",
    "    coverage.sort_values('pct_of_alphaearth', ascending=True),\n",
    "    x='pct_of_alphaearth', y='attribute', orientation='h', text='n_genomes',\n",
    "    title='NCBI Environment Attribute Population Rates (AlphaEarth genomes)',\n",
    "    labels={'pct_of_alphaearth': '% of AlphaEarth genomes', 'attribute': ''},\n",
    ")\n",
    "fig_cov.update_traces(texttemplate='%{text:,}', textposition='outside')\n",
    "fig_cov.update_layout(width=700, height=400)\n",
    "save_fig(fig_cov, 'coverage_bar')\n",
    "fig_cov.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection analysis: which attribute combinations co-occur?\n",
    "upset_cols = {\n",
    "    'Lat/Lon': df['cleaned_lat'].notna() & df['cleaned_lon'].notna(),\n",
    "    'Isolation Source': df['isolation_source'].notna(),\n",
    "    'Env Broad Scale': df['env_broad_scale'].notna(),\n",
    "    'Host': df['host'].notna(),\n",
    "}\n",
    "upset_df = pd.DataFrame(upset_cols)\n",
    "\n",
    "combos = upset_df.groupby(list(upset_df.columns)).size().reset_index(name='count')\n",
    "combos = combos.sort_values('count', ascending=False)\n",
    "combos['label'] = combos.apply(\n",
    "    lambda r: ' + '.join([c for c in upset_df.columns if r[c]]) or 'None', axis=1\n",
    ")\n",
    "\n",
    "fig_int = px.bar(\n",
    "    combos.head(12), x='count', y='label', orientation='h', text='count',\n",
    "    title='Top Metadata Attribute Combinations (UpSet-style)',\n",
    "    labels={'count': 'Number of genomes', 'label': ''},\n",
    ")\n",
    "fig_int.update_traces(texttemplate='%{text:,}', textposition='outside')\n",
    "fig_int.update_layout(width=800, height=450, yaxis={'categoryorder': 'total ascending'})\n",
    "save_fig(fig_int, 'coverage_intersections')\n",
    "fig_int.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The largest group has **all four** attributes (Lat/Lon + Isolation Source + Env Broad Scale + Host) — these are the best-annotated genomes. But a substantial fraction has only Lat/Lon + Isolation Source without ENVO ontology terms or host information. This means `isolation_source` will be our primary environment classifier for most genomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Coordinate Quality Control\n",
    "\n",
    "Geographic coordinates in NCBI are self-reported by submitters. Common problems include:\n",
    "\n",
    "- **Institutional addresses**: Genomes sequenced at a university may have the lab's coordinates instead of the sampling site. This shows up as many diverse species at the exact same location.\n",
    "- **Low-precision coordinates**: Integer-degree values (e.g., 39.0, -77.0) suggest approximate or rounded locations.\n",
    "- **Legitimate sampling sites**: Some locations (e.g., DOE field sites like Rifle, CO or ENIGMA sites) genuinely have many diverse samples collected at the same coordinates. These should not be flagged as suspicious.\n",
    "\n",
    "Our heuristic flags coordinates as **suspicious** if they have >50 genomes AND >10 different species at the exact same location. This is a rough first pass — some flagged sites (like Rifle) are legitimate field research locations with intensive sampling campaigns. A more refined approach would check whether the genomes at each location have consistent isolation sources (homogeneous = real site) vs diverse unrelated sources (heterogeneous = institutional).\n",
    "\n",
    "We also flag **integer-degree coordinates** as low precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_coords = df['cleaned_lat'].notna() & df['cleaned_lon'].notna()\n",
    "coords = df[has_coords].copy()\n",
    "print(f'Genomes with lat/lon: {len(coords):,}')\n",
    "\n",
    "# Round for duplicate detection (4 decimal places ~ 11m precision)\n",
    "coords['lat_round'] = coords['cleaned_lat'].round(4)\n",
    "coords['lon_round'] = coords['cleaned_lon'].round(4)\n",
    "coords['coord_key'] = coords['lat_round'].astype(str) + ',' + coords['lon_round'].astype(str)\n",
    "\n",
    "print(f'Unique coordinate locations: {coords[\"coord_key\"].nunique():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the most-shared coordinates\n",
    "print('Top 15 most-shared coordinates:')\n",
    "print(f'{\"Lat\":>10} {\"Lon\":>10} {\"Genomes\":>8} {\"Species\":>8}  Isolation sources')\n",
    "print('-' * 80)\n",
    "for ck, cnt in coords['coord_key'].value_counts().head(15).items():\n",
    "    mask = coords['coord_key'] == ck\n",
    "    n_sp = coords.loc[mask, 'species'].nunique()\n",
    "    iso_vals = coords.loc[mask, 'isolation_source'].dropna().unique()\n",
    "    iso_str = ', '.join(str(v) for v in iso_vals[:3])[:55]\n",
    "    lat, lon = ck.split(',')\n",
    "    print(f'{lat:>10} {lon:>10} {cnt:>8,} {n_sp:>8}  {iso_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of these are recognizable research sites:\n",
    "- **(39.54, -107.78)**: Rifle, CO — DOE IFRC groundwater research site with extensive metagenomic sampling\n",
    "- **(48.36, -123.30)**: Saanich Inlet, BC — oceanographic time series with oxygen-minimum zone sampling\n",
    "- **(52.11, 79.17)**: Siberian soda lakes — extremophile sampling campaigns\n",
    "\n",
    "Others like **(-12.0, -77.0)** (Lima, Peru — integer coordinates, single species) and **(40.44, -79.97)** (Pittsburgh — diverse clinical samples) look more like institutional coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build quality flags\n",
    "coord_genome_count = coords.groupby('coord_key').size()\n",
    "coord_species_count = coords.groupby('coord_key')['species'].nunique()\n",
    "\n",
    "suspicious_set = set(\n",
    "    coord_genome_count[\n",
    "        (coord_genome_count > 50) & (coord_species_count > 10)\n",
    "    ].index\n",
    ")\n",
    "\n",
    "is_int_lat = (coords['cleaned_lat'] % 1 == 0)\n",
    "is_int_lon = (coords['cleaned_lon'] % 1 == 0)\n",
    "\n",
    "coords['coord_quality'] = 'good'\n",
    "coords.loc[is_int_lat & is_int_lon, 'coord_quality'] = 'low_precision'\n",
    "coords.loc[coords['coord_key'].isin(suspicious_set), 'coord_quality'] = 'suspicious_cluster'\n",
    "\n",
    "# Propagate to main dataframe\n",
    "df['coord_quality'] = 'no_coords'\n",
    "df.loc[coords.index, 'coord_quality'] = coords['coord_quality']\n",
    "\n",
    "print('Coordinate quality distribution:')\n",
    "for q, n in df['coord_quality'].value_counts().items():\n",
    "    print(f'  {q}: {n:,} ({100*n/len(df):.1f}%)')\n",
    "print(f'\\nSuspicious cluster locations: {len(suspicious_set)}')\n",
    "print(f'\\nNote: Some \"suspicious\" locations are legitimate field sites (Rifle, Saanich Inlet, etc.).')\n",
    "print('A refined heuristic should check isolation_source homogeneity at each location.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_qc = px.scatter_geo(\n",
    "    coords, lat='cleaned_lat', lon='cleaned_lon', color='coord_quality',\n",
    "    color_discrete_map={'good': 'green', 'low_precision': 'orange', 'suspicious_cluster': 'red'},\n",
    "    hover_data=['genome_id', 'species', 'isolation_source'],\n",
    "    title='Coordinate Quality Assessment (hover for details)',\n",
    "    opacity=0.5,\n",
    ")\n",
    "fig_qc.update_traces(marker_size=3)\n",
    "fig_qc.update_layout(width=1000, height=600)\n",
    "save_fig(fig_qc, 'coord_quality_map')\n",
    "fig_qc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Environment Label Harmonization\n",
    "\n",
    "The `isolation_source` field contains **5,774 unique free-text values** — everything from \"feces\" to \"permafrost active layer soil\" to \"Rifle well CD01 at 16ft depth\". To make this usable for analysis, we map these to ~12 broad categories using keyword matching.\n",
    "\n",
    "The mapping is intentionally conservative: keywords are checked in order, and the first match wins. Values that don't match any category are labeled \"Other\" — we inspect these to see if the mapping needs expansion.\n",
    "\n",
    "### Category definitions\n",
    "\n",
    "| Category | Example isolation sources |\n",
    "|----------|-------------------------|\n",
    "| Marine | ocean, seawater, marine sediment, coral, hydrothermal |\n",
    "| Freshwater | river, lake, groundwater, drinking water |\n",
    "| Soil | soil, rhizosphere, compost, permafrost, sediment |\n",
    "| Human gut | feces, stool, human intestine, infant feces |\n",
    "| Human clinical | blood, sputum, urine, wound, abscess, patient |\n",
    "| Human other | human skin, oral, saliva, nasal |\n",
    "| Animal | chicken, cattle, fish, insect, rumen |\n",
    "| Plant | leaf, root nodule, phyllosphere, endophyte |\n",
    "| Food | cheese, milk, fermented, kimchi, meat |\n",
    "| Wastewater | sewage, sludge, bioreactor, treatment plant |\n",
    "| Extreme | hot spring, hypersaline, acid mine, soda lake |\n",
    "| Air | air, atmosphere, aerosol, dust |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_CATEGORIES = [\n",
    "    ('Marine', ['ocean', 'marine', 'sea water', 'seawater', 'deep sea', 'coastal water',\n",
    "                'marine sediment', 'coral', 'sponge', 'hydrothermal', 'estuary', 'brackish',\n",
    "                'saline lake', 'salt lake', 'salt marsh', 'mangrove']),\n",
    "    ('Freshwater', ['freshwater', 'fresh water', 'river', 'lake', 'stream', 'pond',\n",
    "                    'spring water', 'groundwater', 'aquifer', 'drinking water', 'tap water',\n",
    "                    'well water']),\n",
    "    ('Soil', ['soil', 'rhizosphere', 'compost', 'peat', 'permafrost', 'sediment', 'mud',\n",
    "              'clay', 'sand', 'agricultural', 'farmland', 'forest soil', 'grassland']),\n",
    "    ('Human gut', ['human gut', 'human feces', 'human fecal', 'human stool', 'human faeces',\n",
    "                   'human faecal', 'human intestin', 'human colon', 'human cecum',\n",
    "                   'human rectal', 'meconium', 'infant fec', 'infant gut', 'feces', 'fecal',\n",
    "                   'faeces', 'faecal', 'stool', 'rectal swab']),\n",
    "    ('Human clinical', ['blood', 'sputum', 'urine', 'wound', 'abscess', 'csf', 'biopsy',\n",
    "                        'bronch', 'patient', 'clinical', 'hospital', 'icu']),\n",
    "    ('Human other', ['human', 'homo sapiens', 'skin', 'oral', 'saliva', 'nasal', 'vaginal',\n",
    "                     'respiratory']),\n",
    "    ('Animal', ['chicken', 'cattle', 'cow', 'pig', 'swine', 'sheep', 'goat', 'horse', 'dog',\n",
    "                'cat', 'mouse', 'rat', 'fish', 'shrimp', 'insect', 'bee', 'ant', 'termite',\n",
    "                'bird', 'poultry', 'animal', 'bovine', 'porcine', 'feline', 'canine', 'avian',\n",
    "                'tick', 'mosquito', 'nematode', 'worm', 'rumen']),\n",
    "    ('Plant', ['plant', 'leaf', 'stem', 'flower', 'fruit', 'seed', 'phyllosphere', 'endophyte',\n",
    "               'epiphyte', 'bark', 'wood', 'crop', 'rice', 'wheat', 'maize', 'corn', 'soybean',\n",
    "               'potato', 'tomato', 'lettuce', 'grape', 'root nodule', 'root']),\n",
    "    ('Food', ['food', 'cheese', 'milk', 'dairy', 'yogurt', 'ferment', 'kimchi', 'sauerkraut',\n",
    "              'wine', 'beer', 'kefir', 'meat', 'sausage', 'bread', 'dough', 'pickle']),\n",
    "    ('Wastewater', ['wastewater', 'waste water', 'sewage', 'sludge', 'activated sludge',\n",
    "                    'bioreactor', 'biogas', 'anaerobic digest', 'treatment plant']),\n",
    "    ('Extreme', ['hot spring', 'thermal', 'geothermal', 'volcanic', 'hypersaline', 'alkaline',\n",
    "                 'acidic', 'acid mine', 'mine drainage', 'glacier', 'ice', 'polar', 'desert',\n",
    "                 'cave', 'soda lake']),\n",
    "    ('Air', ['air', 'atmosphere', 'aerosol', 'dust', 'indoor air']),\n",
    "]\n",
    "\n",
    "\n",
    "def harmonize(value):\n",
    "    \"\"\"Map a raw isolation_source string to a broad category via keyword matching.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return 'Unknown'\n",
    "    vl = str(value).lower().strip()\n",
    "    if vl in ('', 'missing', 'not collected', 'not applicable', 'not available',\n",
    "              'unknown', 'na', 'n/a', 'none'):\n",
    "        return 'Unknown'\n",
    "    for cat, kws in ENV_CATEGORIES:\n",
    "        for kw in kws:\n",
    "            if kw in vl:\n",
    "                return cat\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "df['env_category'] = df['isolation_source'].apply(harmonize)\n",
    "\n",
    "print('Harmonized environment categories:')\n",
    "for cat, count in df['env_category'].value_counts().items():\n",
    "    print(f'  {cat}: {count:,} ({100*count/len(df):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's in \"Other\"? These may need additional keywords.\n",
    "other = df.loc[df['env_category'] == 'Other', 'isolation_source'].value_counts()\n",
    "print(f'\"Other\" category: {(df[\"env_category\"]==\"Other\").sum():,} genomes, '\n",
    "      f'{other.nunique():,} unique values')\n",
    "print(f'\\nTop 20 unmapped isolation sources:')\n",
    "other.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Other\" category contains site-specific labels (\"Aspo HRL\", \"Olkiluoto\" — underground research labs), generic terms (\"water\", \"bodily fluid\", \"tissue\"), and clinical sites (\"cerebrospinal fluid\", \"lung\", \"throat swab\"). Adding more keywords could capture some of these, but the long tail of 3,000+ unique values means there will always be some residual \"Other\".\n",
    "\n",
    "Let's also check whether the ENVO ontology fields (`env_broad_scale`) provide cleaner categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_broad = df['env_broad_scale'].notna().sum()\n",
    "print(f'env_broad_scale coverage: {n_broad:,} ({100*n_broad/len(df):.1f}%)')\n",
    "if n_broad > 0:\n",
    "    print(f'\\nTop 15 env_broad_scale values:')\n",
    "    print(df['env_broad_scale'].value_counts().head(15).to_string())\n",
    "    print(f'\\nNote: Many values are ENVO IDs without labels, or generic terms like '\n",
    "          f'\"not applicable\" and \"missing\". Coverage is lower than isolation_source '\n",
    "          f'but the structured values (e.g., \"marine biome [ENVO:00000447]\") are cleaner.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of harmonized categories\n",
    "cat_counts = df['env_category'].value_counts().reset_index()\n",
    "cat_counts.columns = ['category', 'count']\n",
    "cat_known = cat_counts[~cat_counts['category'].isin(['Unknown'])]\n",
    "\n",
    "fig_cat = px.bar(\n",
    "    cat_known.sort_values('count', ascending=True),\n",
    "    x='count', y='category', orientation='h', text='count',\n",
    "    title='Harmonized Environment Categories (excluding Unknown)',\n",
    "    labels={'count': 'Number of genomes', 'category': ''},\n",
    ")\n",
    "fig_cat.update_traces(texttemplate='%{text:,}', textposition='outside')\n",
    "fig_cat.update_layout(width=700, height=500)\n",
    "save_fig(fig_cat, 'env_categories')\n",
    "fig_cat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key observation\n",
    "\n",
    "The AlphaEarth dataset has a strong **clinical/human bias**: Human clinical (20%) + Human gut (16%) + Human other (2%) = **38%** of genomes are human-associated. Environmental categories (Soil 7%, Marine 7%, Freshwater 7%) are much smaller. This reflects the overall bias in NCBI — clinical pathogens are the most sequenced organisms, and they happen to have good geographic metadata because of epidemiological tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. UMAP of Embedding Space\n",
    "\n",
    "We reduce the 64-dimensional AlphaEarth embeddings to 2D using UMAP for visualization. This reveals whether the embedding space has meaningful structure — clusters, gradients, or separations that correspond to environmental or taxonomic groupings.\n",
    "\n",
    "### Method\n",
    "- L2-normalize embeddings first (so Euclidean distance approximates cosine distance)\n",
    "- Fit UMAP on a 20K subsample for speed, then transform all ~80K points\n",
    "- Parameters: `n_neighbors=15`, `min_dist=0.1`, `metric='euclidean'`\n",
    "\n",
    "If pre-computed UMAP coordinates exist from a previous run, we load those instead to avoid recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to genomes with valid (non-NaN) embeddings\n",
    "valid_mask = ~df[EMB_COLS].isna().any(axis=1)\n",
    "df_clean = df[valid_mask].copy().reset_index(drop=True)\n",
    "print(f'Genomes with valid embeddings: {len(df_clean):,} / {len(df):,} '\n",
    "      f'({len(df) - len(df_clean):,} dropped due to NaN)')\n",
    "\n",
    "# Check for pre-computed UMAP coordinates\n",
    "umap_path = os.path.join(DATA_DIR, 'umap_coords.csv')\n",
    "if os.path.exists(umap_path):\n",
    "    umap_df = pd.read_csv(umap_path)\n",
    "    df_clean = df_clean.merge(umap_df, on='genome_id', how='left')\n",
    "    n_mapped = df_clean['umap_x'].notna().sum()\n",
    "    print(f'Loaded pre-computed UMAP coordinates for {n_mapped:,} genomes')\n",
    "    if n_mapped < len(df_clean) * 0.9:\n",
    "        print('WARNING: Many genomes missing UMAP coords — will recompute')\n",
    "        recompute = True\n",
    "    else:\n",
    "        recompute = False\n",
    "else:\n",
    "    print('No pre-computed UMAP coordinates found — will compute from scratch')\n",
    "    recompute = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute:\n",
    "    embeddings = df_clean[EMB_COLS].values\n",
    "    emb_normed = normalize(embeddings, norm='l2')\n",
    "\n",
    "    # Fit on subsample for speed, transform all\n",
    "    N_FIT = 20_000\n",
    "    np.random.seed(42)\n",
    "    fit_idx = np.random.choice(len(emb_normed), min(N_FIT, len(emb_normed)), replace=False)\n",
    "\n",
    "    print(f'Fitting UMAP on {len(fit_idx):,} subsample...')\n",
    "    reducer = umap.UMAP(\n",
    "        n_components=2, n_neighbors=15, min_dist=0.1,\n",
    "        metric='euclidean', random_state=42,\n",
    "    )\n",
    "    reducer.fit(emb_normed[fit_idx])\n",
    "    print('Transforming all points...')\n",
    "    coords_2d = reducer.transform(emb_normed)\n",
    "\n",
    "    df_clean['umap_x'] = coords_2d[:, 0]\n",
    "    df_clean['umap_y'] = coords_2d[:, 1]\n",
    "\n",
    "    # Save for future runs\n",
    "    df_clean[['genome_id', 'umap_x', 'umap_y']].to_csv(umap_path, index=False)\n",
    "    print(f'Saved UMAP coordinates to {umap_path}')\n",
    "else:\n",
    "    print('Using pre-computed UMAP coordinates.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP colored by environment category\n",
    "\n",
    "If the embeddings encode environmental information, we'd expect genomes from similar environments to cluster together in UMAP space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_env = px.scatter(\n",
    "    df_clean, x='umap_x', y='umap_y', color='env_category',\n",
    "    hover_data=['genome_id', 'species', 'isolation_source', 'cleaned_lat', 'cleaned_lon'],\n",
    "    title='UMAP of AlphaEarth Embeddings — by Environment Category',\n",
    "    opacity=0.4, labels={'umap_x': 'UMAP 1', 'umap_y': 'UMAP 2'},\n",
    ")\n",
    "fig_env.update_traces(marker_size=3)\n",
    "fig_env.update_layout(width=1000, height=700)\n",
    "save_fig(fig_env, 'umap_by_env_category')\n",
    "fig_env.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP colored by phylum\n",
    "\n",
    "Taxonomy provides an alternative lens — do genomes cluster by phylogeny in embedding space? If the embeddings primarily capture *where* organisms live rather than *what* they are, phylogenetic clusters should be weaker than environmental clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_phyla = df_clean['phylum'].value_counts().head(10).index.tolist()\n",
    "df_clean['phylum_display'] = df_clean['phylum'].where(\n",
    "    df_clean['phylum'].isin(top_phyla), 'Other'\n",
    ")\n",
    "\n",
    "fig_phy = px.scatter(\n",
    "    df_clean, x='umap_x', y='umap_y', color='phylum_display',\n",
    "    hover_data=['genome_id', 'species', 'isolation_source'],\n",
    "    title='UMAP of AlphaEarth Embeddings — by Phylum',\n",
    "    opacity=0.4, labels={'umap_x': 'UMAP 1', 'umap_y': 'UMAP 2'},\n",
    ")\n",
    "fig_phy.update_traces(marker_size=3)\n",
    "fig_phy.update_layout(width=1000, height=700)\n",
    "save_fig(fig_phy, 'umap_by_phylum')\n",
    "fig_phy.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP colored by coordinate quality\n",
    "\n",
    "Do genomes with suspicious coordinates occupy specific regions of embedding space? If institutional addresses have consistent satellite imagery (urban land use), they might form their own cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cq = px.scatter(\n",
    "    df_clean, x='umap_x', y='umap_y', color='coord_quality',\n",
    "    color_discrete_map={\n",
    "        'good': 'green', 'low_precision': 'orange',\n",
    "        'suspicious_cluster': 'red', 'no_coords': 'lightgray'\n",
    "    },\n",
    "    hover_data=['genome_id', 'species', 'cleaned_lat', 'cleaned_lon'],\n",
    "    title='UMAP — by Coordinate Quality',\n",
    "    opacity=0.4, labels={'umap_x': 'UMAP 1', 'umap_y': 'UMAP 2'},\n",
    ")\n",
    "fig_cq.update_traces(marker_size=3)\n",
    "fig_cq.update_layout(width=1000, height=700)\n",
    "save_fig(fig_cq, 'umap_by_coord_quality')\n",
    "fig_cq.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Geographic Map\n",
    "\n",
    "Where in the world are these genomes from? The interactive map lets you zoom into specific regions and hover for genome details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = df_clean[df_clean['cleaned_lat'].notna()].copy()\n",
    "print(f'Genomes with coordinates: {len(geo_df):,}')\n",
    "\n",
    "fig_map = px.scatter_geo(\n",
    "    geo_df, lat='cleaned_lat', lon='cleaned_lon', color='env_category',\n",
    "    hover_data=['genome_id', 'species', 'isolation_source', 'phylum'],\n",
    "    title='Global Distribution of AlphaEarth Genomes — by Environment',\n",
    "    opacity=0.5,\n",
    ")\n",
    "fig_map.update_traces(marker_size=3)\n",
    "fig_map.update_layout(width=1100, height=600)\n",
    "save_fig(fig_map, 'global_map_by_env')\n",
    "fig_map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Embedding Distance vs Geographic Distance\n",
    "\n",
    "A key question: **do the AlphaEarth embeddings capture geographic proximity?** If satellite imagery at two locations is similar (similar climate, land use, vegetation), the embeddings should be close in cosine distance, even if the locations are far apart geographically.\n",
    "\n",
    "Conversely, if the embeddings mainly encode *location* rather than *environment type*, we'd expect a strong monotonic relationship between geographic distance and embedding distance.\n",
    "\n",
    "We sample 50K random genome pairs (using only good-quality coordinates) and compute both distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = df_clean[\n",
    "    (df_clean['coord_quality'] == 'good') & df_clean['cleaned_lat'].notna()\n",
    "].copy()\n",
    "print(f'Genomes with good coordinates: {len(good):,}')\n",
    "\n",
    "# Sample random pairs\n",
    "np.random.seed(42)\n",
    "n = len(good)\n",
    "idx1 = np.random.randint(0, n, size=50_000)\n",
    "idx2 = np.random.randint(0, n, size=50_000)\n",
    "mask = idx1 != idx2\n",
    "idx1, idx2 = idx1[mask], idx2[mask]\n",
    "print(f'Sampled {len(idx1):,} random pairs')\n",
    "\n",
    "# Haversine geographic distance\n",
    "lats, lons = good['cleaned_lat'].values, good['cleaned_lon'].values\n",
    "R = 6371  # Earth radius km\n",
    "lat1r, lon1r = np.radians(lats[idx1]), np.radians(lons[idx1])\n",
    "lat2r, lon2r = np.radians(lats[idx2]), np.radians(lons[idx2])\n",
    "dlat, dlon = lat2r - lat1r, lon2r - lon1r\n",
    "a = np.sin(dlat/2)**2 + np.cos(lat1r) * np.cos(lat2r) * np.sin(dlon/2)**2\n",
    "geo_dist = 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "# Cosine distance between embeddings (vectorized)\n",
    "emb = good[EMB_COLS].values\n",
    "dots = np.sum(emb[idx1] * emb[idx2], axis=1)\n",
    "norms1 = np.linalg.norm(emb[idx1], axis=1)\n",
    "norms2 = np.linalg.norm(emb[idx2], axis=1)\n",
    "emb_dist = 1 - dots / (norms1 * norms2 + 1e-10)\n",
    "\n",
    "same_sp = good['species'].values[idx1] == good['species'].values[idx2]\n",
    "\n",
    "pairs = pd.DataFrame({\n",
    "    'geo_dist_km': geo_dist, 'emb_cosine_dist': emb_dist, 'same_species': same_sp\n",
    "})\n",
    "print(f'Same-species pairs: {same_sp.sum():,} ({100*same_sp.mean():.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dist = px.scatter(\n",
    "    pairs.sample(10_000, random_state=42),\n",
    "    x='geo_dist_km', y='emb_cosine_dist', color='same_species',\n",
    "    color_discrete_map={True: 'blue', False: 'gray'},\n",
    "    title='Geographic Distance vs Embedding Distance (good coords, 10K sample)',\n",
    "    labels={'geo_dist_km': 'Geographic Distance (km)',\n",
    "            'emb_cosine_dist': 'Embedding Cosine Distance',\n",
    "            'same_species': 'Same Species'},\n",
    "    opacity=0.3,\n",
    ")\n",
    "fig_dist.update_traces(marker_size=3)\n",
    "fig_dist.update_layout(width=900, height=600)\n",
    "save_fig(fig_dist, 'geo_vs_embedding_distance')\n",
    "fig_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binned analysis for clearer trend\n",
    "pairs['geo_bin'] = pd.cut(\n",
    "    pairs['geo_dist_km'],\n",
    "    bins=[0, 100, 500, 1000, 2000, 5000, 10000, 20000],\n",
    "    labels=['<100', '100-500', '500-1K', '1K-2K', '2K-5K', '5K-10K', '10K-20K']\n",
    ")\n",
    "binned = pairs.groupby('geo_bin', observed=True).agg(\n",
    "    mean_emb=('emb_cosine_dist', 'mean'),\n",
    "    median_emb=('emb_cosine_dist', 'median'),\n",
    "    n=('emb_cosine_dist', 'count'),\n",
    ").reset_index()\n",
    "\n",
    "print('Mean embedding distance by geographic distance bin:')\n",
    "print(binned.to_string(index=False))\n",
    "\n",
    "fig_bin = px.bar(\n",
    "    binned, x='geo_bin', y='mean_emb', text='n',\n",
    "    title='Mean Embedding Distance by Geographic Distance',\n",
    "    labels={'geo_bin': 'Geographic Distance (km)', 'mean_emb': 'Mean Cosine Distance'},\n",
    ")\n",
    "fig_bin.update_traces(texttemplate='n=%{text:,}', textposition='outside')\n",
    "fig_bin.update_layout(width=800, height=500)\n",
    "save_fig(fig_bin, 'geo_vs_embedding_binned')\n",
    "fig_bin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key finding\n",
    "\n",
    "There is a **clear monotonic relationship** between geographic distance and embedding distance:\n",
    "\n",
    "| Distance | Mean Cosine Distance |\n",
    "|----------|---------------------|\n",
    "| <100 km | ~0.41 |\n",
    "| 500–1K km | ~0.56 |\n",
    "| 5K–10K km | ~0.80 |\n",
    "| 10K–20K km | ~0.82 |\n",
    "\n",
    "Nearby genomes have **substantially more similar embeddings**. The relationship is strongest at short distances (<2000 km) and plateaus at intercontinental distances (>5000 km). This confirms that AlphaEarth embeddings encode **real geographic/environmental signal**, not noise.\n",
    "\n",
    "The plateau suggests that the embeddings capture local environmental conditions (climate, land use) more than global position — genomes 5000 km apart are about as different as genomes 20000 km apart, because at those distances, the environments are essentially random draws from the global distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Embedding Cluster × Environment Cross-Tabulation\n",
    "\n",
    "We cluster the UMAP space with DBSCAN and check whether clusters correspond to environment categories. If the embeddings encode environment type, we'd expect each cluster to be dominated by one or a few categories.\n",
    "\n",
    "DBSCAN parameters (`eps=0.5`, `min_samples=50`) are a first pass — the number and granularity of clusters may need tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_xy = df_clean[['umap_x', 'umap_y']].dropna().values\n",
    "valid_umap = df_clean['umap_x'].notna()\n",
    "\n",
    "clustering = DBSCAN(eps=0.5, min_samples=50).fit(umap_xy)\n",
    "df_clean.loc[valid_umap, 'umap_cluster'] = clustering.labels_\n",
    "\n",
    "n_clusters = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)\n",
    "n_noise = (clustering.labels_ == -1).sum()\n",
    "print(f'DBSCAN found {n_clusters} clusters + {n_noise:,} noise points')\n",
    "print(f'\\nLargest 10 clusters:')\n",
    "cluster_sizes = pd.Series(clustering.labels_).value_counts()\n",
    "for label, size in cluster_sizes.head(11).items():\n",
    "    if label == -1:\n",
    "        continue\n",
    "    print(f'  Cluster {label}: {size:,} genomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['cl_str'] = df_clean['umap_cluster'].fillna(-1).astype(int).astype(str)\n",
    "df_clean.loc[df_clean['umap_cluster'].fillna(-1) == -1, 'cl_str'] = 'noise'\n",
    "\n",
    "fig_cl = px.scatter(\n",
    "    df_clean[valid_umap], x='umap_x', y='umap_y', color='cl_str',\n",
    "    hover_data=['genome_id', 'species', 'env_category', 'isolation_source'],\n",
    "    title=f'UMAP Clusters (DBSCAN: {n_clusters} clusters)',\n",
    "    opacity=0.4,\n",
    "    labels={'umap_x': 'UMAP 1', 'umap_y': 'UMAP 2', 'cl_str': 'Cluster'},\n",
    ")\n",
    "fig_cl.update_traces(marker_size=3)\n",
    "fig_cl.update_layout(width=1000, height=700, showlegend=False)\n",
    "save_fig(fig_cl, 'umap_clusters')\n",
    "fig_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation: what environment categories make up each cluster?\n",
    "xtab_df = df_clean[\n",
    "    (df_clean['umap_cluster'].fillna(-1) >= 0) &\n",
    "    (df_clean['env_category'] != 'Unknown')\n",
    "].copy()\n",
    "xtab_df['umap_cluster'] = xtab_df['umap_cluster'].astype(int)\n",
    "\n",
    "# Only show largest clusters for readability\n",
    "top_clusters = xtab_df['umap_cluster'].value_counts().head(20).index.tolist()\n",
    "xtab_top = xtab_df[xtab_df['umap_cluster'].isin(top_clusters)]\n",
    "\n",
    "xtab = pd.crosstab(xtab_top['env_category'], xtab_top['umap_cluster'], normalize='columns')\n",
    "\n",
    "fig_h = px.imshow(\n",
    "    xtab, title='Environment Category Composition of Top 20 Clusters (column-normalized)',\n",
    "    labels={'x': 'UMAP Cluster', 'y': 'Environment Category', 'color': 'Fraction'},\n",
    "    aspect='auto', color_continuous_scale='Blues',\n",
    ")\n",
    "fig_h.update_layout(width=900, height=500)\n",
    "save_fig(fig_h, 'cluster_env_heatmap')\n",
    "fig_h.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse view: for each environment category, which clusters contain its genomes?\n",
    "xtab_row = pd.crosstab(xtab_top['env_category'], xtab_top['umap_cluster'], normalize='index')\n",
    "\n",
    "fig_hr = px.imshow(\n",
    "    xtab_row, title='Cluster Distribution per Environment Category (row-normalized)',\n",
    "    labels={'x': 'UMAP Cluster', 'y': 'Environment Category', 'color': 'Fraction'},\n",
    "    aspect='auto', color_continuous_scale='Oranges',\n",
    ")\n",
    "fig_hr.update_layout(width=900, height=500)\n",
    "save_fig(fig_hr, 'env_cluster_distribution')\n",
    "fig_hr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### What we found\n",
    "\n",
    "1. **Data coverage**: Nearly all AlphaEarth genomes have lat/lon (100%) and isolation_source (92%). ENVO ontology terms cover ~40%. Strong clinical/human bias (38% of genomes).\n",
    "\n",
    "2. **Coordinate quality**: ~36% of genomes cluster at shared coordinates. Some are legitimate field sites (Rifle, Saanich Inlet), others are likely institutional addresses. The current QC heuristic needs refinement to distinguish these cases.\n",
    "\n",
    "3. **Environment harmonization**: 5,774 unique isolation_source values mapped to 12 broad categories. ~17% remain as \"Other\" — these are site-specific labels, generic terms, or clinical sites that could be captured with additional keywords.\n",
    "\n",
    "4. **Embedding structure**: The 64-dim space shows structure in UMAP, with 320 clusters (DBSCAN). The large number of clusters suggests the embeddings encode fine-grained environmental variation, not just broad categories.\n",
    "\n",
    "5. **Geography–embedding relationship**: **Strong monotonic correlation** — genomes <100km apart have cosine distance ~0.41, while intercontinental pairs have ~0.82. This confirms the embeddings encode real environmental/geographic signal.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "- Refine coordinate QC to distinguish legitimate field sites from institutional addresses\n",
    "- Reduce \"Other\" category by adding more keywords or using `env_broad_scale` as a fallback\n",
    "- Tune DBSCAN parameters for coarser clusters that map more cleanly onto environment categories\n",
    "- Investigate what the individual embedding dimensions represent (correlation with latitude, temperature, precipitation, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Analysis complete ===')\n",
    "print(f'\\nGenomes: {len(df):,} total, {len(df_clean):,} with valid embeddings')\n",
    "print(f'Coord quality: good={sum(df[\"coord_quality\"]==\"good\"):,}, '\n",
    "      f'suspicious={sum(df[\"coord_quality\"]==\"suspicious_cluster\"):,}')\n",
    "print(f'\\nFigures saved:')\n",
    "for f in sorted(os.listdir(FIG_DIR)):\n",
    "    if not f.startswith('.'):\n",
    "        sz = os.path.getsize(os.path.join(FIG_DIR, f)) / 1e6\n",
    "        print(f'  {f} ({sz:.1f} MB)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
