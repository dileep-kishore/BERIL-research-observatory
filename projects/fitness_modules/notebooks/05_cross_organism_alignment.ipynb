{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB 05: Cross-Organism Module Alignment\n",
    "\n",
    "Group modules from different organisms into conserved \"module families\"\n",
    "using ortholog fingerprints.\n",
    "\n",
    "Steps:\n",
    "1. Extract BBH pairs from `ortholog` table\n",
    "2. Build ortholog groups (OGs) via connected components\n",
    "3. Convert each module → OG fingerprint\n",
    "4. Cluster into module families by cosine similarity\n",
    "5. Consensus annotations for families\n",
    "\n",
    "**Part 1 (JupyterHub)**: Extract ortholog pairs.\n",
    "**Part 2 (local)**: Build OGs and align modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T08:08:17.699366Z",
     "iopub.status.busy": "2026-02-13T08:08:17.699251Z",
     "iopub.status.idle": "2026-02-13T08:08:18.256874Z",
     "shell.execute_reply": "2026-02-13T08:08:18.255958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilot organisms: ['DvH', 'Btheta', 'Methanococcus_S2', 'psRCH2', 'Putida', 'Phaeo', 'Marino', 'pseudo3_N2E3', 'Koxy', 'Cola', 'WCS417', 'Caulo', 'SB2B', 'pseudo6_N2E2', 'Dino', 'pseudo5_N2C3_1', 'Miya', 'Pedo557', 'MR1', 'Keio', 'Korea', 'PV4', 'pseudo1_N1B4', 'acidovorax_3H11', 'SynE', 'Methanococcus_JJ', 'BFirm', 'Kang', 'ANA3', 'Cup4G11', 'pseudo13_GW456_L13', 'Ponti']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "MODULE_DIR = DATA_DIR / 'modules'\n",
    "ORTHO_DIR = DATA_DIR / 'orthologs'\n",
    "FAMILY_DIR = DATA_DIR / 'module_families'\n",
    "ORTHO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FAMILY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pilots = pd.read_csv(DATA_DIR / 'pilot_organisms.csv')\n",
    "pilot_ids = pilots['orgId'].tolist()\n",
    "print(f\"Pilot organisms: {pilot_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Extract BBH Ortholog Pairs (Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T08:08:18.310243Z",
     "iopub.status.busy": "2026-02-13T08:08:18.310056Z",
     "iopub.status.idle": "2026-02-13T08:08:19.449787Z",
     "shell.execute_reply": "2026-02-13T08:08:19.448760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1148966 cached BBH pairs\n"
     ]
    }
   ],
   "source": [
    "bbh_file = ORTHO_DIR / 'pilot_bbh_pairs.csv'\n",
    "\n",
    "try:\n",
    "    spark = get_spark_session()\n",
    "    HAS_SPARK = True\n",
    "    print(f\"Spark version: {spark.version}\")\n",
    "except Exception:\n",
    "    HAS_SPARK = False\n",
    "    print(\"No Spark — using cached data\")\n",
    "\n",
    "if HAS_SPARK and not (bbh_file.exists() and bbh_file.stat().st_size > 0):\n",
    "    # Build SQL filter for pilot organisms\n",
    "    org_list = \", \".join([f\"'{o}'\" for o in pilot_ids])\n",
    "    \n",
    "    bbh = spark.sql(f\"\"\"\n",
    "        SELECT orgId1, locusId1, orgId2, locusId2,\n",
    "               CAST(ratio AS FLOAT) as ratio\n",
    "        FROM kescience_fitnessbrowser.ortholog\n",
    "        WHERE orgId1 IN ({org_list})\n",
    "          AND orgId2 IN ({org_list})\n",
    "    \"\"\").toPandas()\n",
    "    bbh.to_csv(bbh_file, index=False)\n",
    "    print(f\"Extracted {len(bbh)} BBH pairs among pilot organisms\")\n",
    "else:\n",
    "    bbh = pd.read_csv(bbh_file)\n",
    "    print(f\"Loaded {len(bbh)} cached BBH pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Build Ortholog Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T08:08:19.452482Z",
     "iopub.status.busy": "2026-02-13T08:08:19.452342Z",
     "iopub.status.idle": "2026-02-13T08:08:19.532618Z",
     "shell.execute_reply": "2026-02-13T08:08:19.531699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACHED: 13402 ortholog groups\n",
      "\n",
      "OG size: median=3, max=1189\n",
      "OGs spanning 2+ organisms: 13402\n",
      "OGs spanning all 32 pilots: 108\n"
     ]
    }
   ],
   "source": [
    "og_file = ORTHO_DIR / 'ortholog_groups.csv'\n",
    "\n",
    "if og_file.exists() and og_file.stat().st_size > 0:\n",
    "    og_df = pd.read_csv(og_file)\n",
    "    print(f\"CACHED: {og_df['OG_id'].nunique()} ortholog groups\")\n",
    "else:\n",
    "    # Build graph: nodes = (orgId, locusId), edges = BBH pairs\n",
    "    G = nx.Graph()\n",
    "    for _, row in bbh.iterrows():\n",
    "        n1 = f\"{row['orgId1']}:{row['locusId1']}\"\n",
    "        n2 = f\"{row['orgId2']}:{row['locusId2']}\"\n",
    "        G.add_edge(n1, n2, weight=row['ratio'])\n",
    "    \n",
    "    print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # Connected components = ortholog groups\n",
    "    components = list(nx.connected_components(G))\n",
    "    print(f\"Ortholog groups: {len(components)}\")\n",
    "    \n",
    "    og_records = []\n",
    "    for og_id, comp in enumerate(components):\n",
    "        for node in comp:\n",
    "            org, locus = node.split(':', 1)\n",
    "            og_records.append({'OG_id': f'OG{og_id:05d}', 'orgId': org, 'locusId': locus})\n",
    "    \n",
    "    og_df = pd.DataFrame(og_records)\n",
    "    og_df.to_csv(og_file, index=False)\n",
    "    print(f\"Saved {len(og_df)} gene-OG assignments ({og_df['OG_id'].nunique()} OGs)\")\n",
    "\n",
    "# Summary\n",
    "og_sizes = og_df.groupby('OG_id').size()\n",
    "og_org_count = og_df.groupby('OG_id')['orgId'].nunique()\n",
    "print(f\"\\nOG size: median={og_sizes.median():.0f}, max={og_sizes.max()}\")\n",
    "print(f\"OGs spanning 2+ organisms: {(og_org_count >= 2).sum()}\")\n",
    "print(f\"OGs spanning all {len(pilot_ids)} pilots: {(og_org_count >= len(pilot_ids)).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Module → OG Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T08:08:19.534897Z",
     "iopub.status.busy": "2026-02-13T08:08:19.534775Z",
     "iopub.status.idle": "2026-02-13T08:08:34.228873Z",
     "shell.execute_reply": "2026-02-13T08:08:34.227893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint dimensionality: 13402 OGs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fingerprint matrix: 1114 modules × 13402 OGs\n",
      "Non-zero entries: 28043 / 14929828 (0.2%)\n"
     ]
    }
   ],
   "source": [
    "# Get all OG IDs for fingerprint vector\n",
    "all_ogs = sorted(og_df['OG_id'].unique())\n",
    "og_to_idx = {og: i for i, og in enumerate(all_ogs)}\n",
    "n_ogs = len(all_ogs)\n",
    "print(f\"Fingerprint dimensionality: {n_ogs} OGs\")\n",
    "\n",
    "# Build gene→OG lookup per organism\n",
    "gene_to_og = {}\n",
    "for _, row in og_df.iterrows():\n",
    "    key = (row['orgId'], str(row['locusId']))\n",
    "    gene_to_og[key] = row['OG_id']\n",
    "\n",
    "# Build fingerprints for all modules across all organisms\n",
    "module_fingerprints = []\n",
    "module_labels = []\n",
    "\n",
    "for org_id in pilot_ids:\n",
    "    weights_file = MODULE_DIR / f'{org_id}_gene_weights.csv'\n",
    "    member_file = MODULE_DIR / f'{org_id}_gene_membership.csv'\n",
    "    \n",
    "    if not member_file.exists():\n",
    "        print(f\"Skipping {org_id} — no modules\")\n",
    "        continue\n",
    "    \n",
    "    weights = pd.read_csv(weights_file, index_col=0)\n",
    "    membership = pd.read_csv(member_file, index_col=0)\n",
    "    \n",
    "    for mod in membership.columns:\n",
    "        mod_genes = membership.index[membership[mod] == 1].astype(str)\n",
    "        if len(mod_genes) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Build OG fingerprint weighted by |gene_weight|\n",
    "        fingerprint = np.zeros(n_ogs)\n",
    "        for gene in mod_genes:\n",
    "            og = gene_to_og.get((org_id, gene))\n",
    "            if og and og in og_to_idx:\n",
    "                w = abs(weights.loc[weights.index.astype(str) == gene, mod].values[0])\n",
    "                fingerprint[og_to_idx[og]] += w\n",
    "        \n",
    "        if fingerprint.sum() > 0:\n",
    "            module_fingerprints.append(fingerprint)\n",
    "            module_labels.append({'orgId': org_id, 'module': mod})\n",
    "\n",
    "fp_matrix = np.array(module_fingerprints)\n",
    "label_df = pd.DataFrame(module_labels)\n",
    "print(f\"\\nFingerprint matrix: {fp_matrix.shape[0]} modules × {fp_matrix.shape[1]} OGs\")\n",
    "print(f\"Non-zero entries: {(fp_matrix > 0).sum()} / {fp_matrix.size} ({(fp_matrix > 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster into Module Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T08:08:34.231464Z",
     "iopub.status.busy": "2026-02-13T08:08:34.231339Z",
     "iopub.status.idle": "2026-02-13T08:09:31.843158Z",
     "shell.execute_reply": "2026-02-13T08:09:31.842209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total families: 749\n",
      "Families spanning 2+ organisms: 156\n",
      "Saved: module_families.csv\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity between modules from DIFFERENT organisms only\n",
    "cos_sim = cosine_similarity(fp_matrix)\n",
    "\n",
    "# Mask within-organism similarities (set to 0)\n",
    "for i in range(len(label_df)):\n",
    "    for j in range(len(label_df)):\n",
    "        if label_df.iloc[i]['orgId'] == label_df.iloc[j]['orgId']:\n",
    "            cos_sim[i, j] = 0 if i != j else 1\n",
    "\n",
    "# Hierarchical clustering on cosine distance\n",
    "cos_dist = 1 - np.abs(cos_sim)\n",
    "np.fill_diagonal(cos_dist, 0)\n",
    "cos_dist = np.clip(cos_dist, 0, 1)  # numerical safety\n",
    "\n",
    "condensed = squareform(cos_dist)\n",
    "Z = linkage(condensed, method='average')\n",
    "\n",
    "# Cut at distance threshold to define families\n",
    "family_labels = fcluster(Z, t=0.7, criterion='distance')\n",
    "label_df['familyId'] = [f'F{f:03d}' for f in family_labels]\n",
    "\n",
    "# Keep only families spanning 2+ organisms\n",
    "family_org_count = label_df.groupby('familyId')['orgId'].nunique()\n",
    "multi_org_families = family_org_count[family_org_count >= 2].index\n",
    "print(f\"Total families: {label_df['familyId'].nunique()}\")\n",
    "print(f\"Families spanning 2+ organisms: {len(multi_org_families)}\")\n",
    "\n",
    "label_df.to_csv(FAMILY_DIR / 'module_families.csv', index=False)\n",
    "print(f\"Saved: module_families.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Consensus Annotations for Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T08:09:31.845572Z",
     "iopub.status.busy": "2026-02-13T08:09:31.845451Z",
     "iopub.status.idle": "2026-02-13T08:09:32.662046Z",
     "shell.execute_reply": "2026-02-13T08:09:32.661228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Family annotation summary:\n",
      "  Annotated families: 32\n",
      "  Unannotated families: 124\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>familyId</th>\n",
       "      <th>n_organisms</th>\n",
       "      <th>n_modules</th>\n",
       "      <th>consensus_term</th>\n",
       "      <th>consensus_db</th>\n",
       "      <th>term_organisms</th>\n",
       "      <th>mean_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>TIGR01539</td>\n",
       "      <td>TIGRFam</td>\n",
       "      <td>1</td>\n",
       "      <td>2.975088e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F026</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Nitrogen regulatory protein P-II</td>\n",
       "      <td>SEED</td>\n",
       "      <td>1</td>\n",
       "      <td>4.230792e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F029</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F034</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F044</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F045</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F046</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F050</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F055</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unannotated</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  familyId  n_organisms  n_modules                    consensus_term  \\\n",
       "0     F001            2          2                         TIGR01539   \n",
       "1     F026            3          3  Nitrogen regulatory protein P-II   \n",
       "2     F029            2          2                       unannotated   \n",
       "3     F031            2          2                       unannotated   \n",
       "4     F034            2          2                       unannotated   \n",
       "5     F044            2          2                       unannotated   \n",
       "6     F045            2          2                       unannotated   \n",
       "7     F046            3          3                       unannotated   \n",
       "8     F050            2          2                       unannotated   \n",
       "9     F055            2          2                       unannotated   \n",
       "\n",
       "  consensus_db  term_organisms      mean_fdr  \n",
       "0      TIGRFam               1  2.975088e-07  \n",
       "1         SEED               1  4.230792e-04  \n",
       "2                            0  1.000000e+00  \n",
       "3                            0  1.000000e+00  \n",
       "4                            0  1.000000e+00  \n",
       "5                            0  1.000000e+00  \n",
       "6                            0  1.000000e+00  \n",
       "7                            0  1.000000e+00  \n",
       "8                            0  1.000000e+00  \n",
       "9                            0  1.000000e+00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each multi-organism family, collect module annotations and find consensus\n",
    "family_annotations = []\n",
    "\n",
    "for fam_id in multi_org_families:\n",
    "    fam_modules = label_df[label_df['familyId'] == fam_id]\n",
    "    \n",
    "    # Collect all significant enrichments from member modules\n",
    "    all_terms = []\n",
    "    for _, row in fam_modules.iterrows():\n",
    "        ann_file = MODULE_DIR / f\"{row['orgId']}_module_annotations.csv\"\n",
    "        if not ann_file.exists() or ann_file.stat().st_size < 10:\n",
    "            continue\n",
    "        ann = pd.read_csv(ann_file)\n",
    "        if len(ann) == 0:\n",
    "            continue\n",
    "        mod_ann = ann[(ann['module'] == row['module']) & (ann['significant'] == True)]\n",
    "        for _, a in mod_ann.iterrows():\n",
    "            all_terms.append({\n",
    "                'term': a['term'],\n",
    "                'database': a['database'],\n",
    "                'orgId': row['orgId'],\n",
    "                'fdr': a['fdr']\n",
    "            })\n",
    "    \n",
    "    if not all_terms:\n",
    "        family_annotations.append({\n",
    "            'familyId': fam_id,\n",
    "            'n_organisms': len(fam_modules['orgId'].unique()),\n",
    "            'n_modules': len(fam_modules),\n",
    "            'consensus_term': 'unannotated',\n",
    "            'consensus_db': '',\n",
    "            'term_organisms': 0,\n",
    "            'mean_fdr': 1.0\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    terms_df = pd.DataFrame(all_terms)\n",
    "    \n",
    "    # Consensus: term appearing in most organisms with best mean FDR\n",
    "    term_stats = terms_df.groupby(['term', 'database']).agg(\n",
    "        term_organisms=('orgId', 'nunique'),\n",
    "        mean_fdr=('fdr', 'mean')\n",
    "    ).reset_index()\n",
    "    term_stats = term_stats.sort_values(['term_organisms', 'mean_fdr'],\n",
    "                                        ascending=[False, True])\n",
    "    best = term_stats.iloc[0]\n",
    "    \n",
    "    family_annotations.append({\n",
    "        'familyId': fam_id,\n",
    "        'n_organisms': len(fam_modules['orgId'].unique()),\n",
    "        'n_modules': len(fam_modules),\n",
    "        'consensus_term': best['term'],\n",
    "        'consensus_db': best['database'],\n",
    "        'term_organisms': int(best['term_organisms']),\n",
    "        'mean_fdr': best['mean_fdr']\n",
    "    })\n",
    "\n",
    "fam_ann_df = pd.DataFrame(family_annotations)\n",
    "fam_ann_df.to_csv(FAMILY_DIR / 'family_annotations.csv', index=False)\n",
    "print(f\"\\nFamily annotation summary:\")\n",
    "print(f\"  Annotated families: {(fam_ann_df['consensus_term'] != 'unannotated').sum()}\")\n",
    "print(f\"  Unannotated families: {(fam_ann_df['consensus_term'] == 'unannotated').sum()}\")\n",
    "fam_ann_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
